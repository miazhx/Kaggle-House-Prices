{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matplotlib\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "def data_process(test=False):\n",
    "    \n",
    "    \n",
    "    # Read file for train or test.\n",
    "    \n",
    "    df_raw_train = pd.read_csv('train.csv',index_col=0)\n",
    "    df_raw_test = pd.read_csv('test.csv',index_col=0)\n",
    "\n",
    "    \n",
    "    # Remove outliers in training set.   \n",
    "    outlier_list_scatter = [524, 1299]\n",
    "    outlier_list_hard_to_fit = [463, 31, 534, 1433, 739, 1159, 108, 1231, 971, 1424 ]\n",
    "    outlier_list = outlier_list_scatter + outlier_list_hard_to_fit\n",
    "    df_raw_train = df_raw_train.drop(outlier_list)\n",
    "    \n",
    "    # Store the sale price information\n",
    "    sale_price_train = df_raw_train['SalePrice']\n",
    "    \n",
    "    # Merge train and test df together for later process\n",
    "    df_processed = pd.concat([df_raw_train, df_raw_test], sort=True)\n",
    "    \n",
    "\n",
    "    # Combine bathroom quanlitity \n",
    "    df_processed['BsmtBath'] = df_processed.BsmtFullBath + df_processed.BsmtHalfBath * 0.5\n",
    "    df_processed['Bath'] = df_processed.FullBath + df_processed.HalfBath * 0.5\n",
    "       \n",
    "    \n",
    "    ## Drop multicollinear columns \n",
    "    df_processed = df_processed.drop(['BsmtFullBath', 'BsmtHalfBath','FullBath','HalfBath'], axis=1)\n",
    "    \n",
    "    \n",
    "    ## Missing values\n",
    "    \n",
    "    # 259 LotFrontage  - replace missing value with 0 \n",
    "#     df_processed.LotFrontage = df_processed.LotFrontage.fillna(0)\n",
    "    df_processed[\"LotFrontage\"] = df_processed.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    # 1369 Alley - replace with None\n",
    "    df_processed.Alley = df_processed.Alley.fillna('None')\n",
    "\n",
    "    # 8 MasVnrType and MasVnrArea - replace MasVnrType with None and MasVnrArea with 0\n",
    "    df_processed.MasVnrType = df_processed.MasVnrType.fillna('None')\n",
    "    df_processed.MasVnrArea = df_processed.MasVnrArea.fillna(0)\n",
    "\n",
    "    # 37 basement: BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2- replace with None\n",
    "    df_processed.BsmtQual = df_processed.BsmtQual.fillna('None')\n",
    "    df_processed.BsmtCond = df_processed.BsmtCond.fillna('None')\n",
    "    df_processed.BsmtExposure = df_processed.BsmtExposure.fillna('None')\n",
    "    df_processed.BsmtFinType1 = df_processed.BsmtFinType1.fillna('None')\n",
    "    df_processed.BsmtFinType2 = df_processed.BsmtFinType2.fillna('None')\n",
    "    df_processed.TotalBsmtSF = df_processed.TotalBsmtSF.fillna(0)\n",
    "    \n",
    "\n",
    "    # 690 FireplaceQu - replace with None\n",
    "    df_processed.FireplaceQu = df_processed.FireplaceQu.fillna('None')\n",
    "\n",
    "    # 81 Garage: GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond - replace with None and year with 0 \n",
    "    df_processed.GarageType = df_processed.GarageType.fillna('None')\n",
    "    df_processed.GarageFinish = df_processed.GarageFinish.fillna('None')\n",
    "    df_processed.GarageQual = df_processed.GarageQual.fillna('None')\n",
    "    df_processed.GarageCond = df_processed.GarageCond.fillna('None')\n",
    "    df_processed.GarageYrBlt = df_processed.GarageYrBlt.fillna(0)\n",
    "\n",
    "    # 1453 PoolQC - replace with None\n",
    "    df_processed.PoolQC = df_processed.PoolQC.fillna('None')\n",
    "\n",
    "    # 1179 Fence - replace with None\n",
    "    df_processed.Fence = df_processed.Fence.fillna('None')\n",
    "\n",
    "    # 1406 MiscFeature - replace with None    \n",
    "    df_processed.MiscFeature = df_processed.MiscFeature.fillna('None')\n",
    "\n",
    "    # 1 Electrical\n",
    "    df_processed = df_processed[pd.notnull(df_processed.Electrical)]\n",
    "    \n",
    "    #Missing Value only in test data \n",
    "    \n",
    "    # MSZoning (The general zoning classification) : 'RL' is by far the most common value. So we can fill in missing values with 'RL'\n",
    "    df_processed['MSZoning'] = df_processed['MSZoning'].fillna(df_processed['MSZoning'].mode()[0])\n",
    "\n",
    "    # Utilities : For this categorical feature all records are \"AllPub\", except for one \"NoSeWa\" and 2 NA . Since the house with 'NoSewa' is in the training set, this feature won't help in predictive modelling. We can then safely remove it.\n",
    "    df_processed.drop(['Utilities'], axis=1,inplace=True)\n",
    "\n",
    "    # Exterior1st and Exterior2nd : Again Both Exterior 1 & 2 have only one missing value. We will just substitute in the most common string\n",
    "    df_processed['Exterior1st'] = df_processed['Exterior1st'].fillna(df_processed['Exterior1st'].mode()[0])\n",
    "    df_processed['Exterior2nd'] = df_processed['Exterior2nd'].fillna(df_processed['Exterior2nd'].mode()[0]) \n",
    "    \n",
    "    # BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtBath : missing values are likely zero for having no basement\n",
    "    for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtBath'):\n",
    "        df_processed[col] = df_processed[col].fillna(0)    \n",
    "    \n",
    "    #Garage Cars \n",
    "    df_processed.GarageCars = df_processed.GarageCars.fillna(0) \n",
    "    \n",
    "    # SaleType : Fill in again with most frequent which is \"WD\"\n",
    "    df_processed['SaleType'] = df_processed['SaleType'].fillna(df_processed['SaleType'].mode()[0])\n",
    "    \n",
    "    # KitchenQual: Only one NA value, and same as Electrical, we set 'TA' (which is the most frequent) for the missing value in KitchenQual.\n",
    "    df_processed['KitchenQual'] = df_processed['KitchenQual'].fillna(df_processed['KitchenQual'].mode()[0])    \n",
    "    \n",
    "    # Functional : data description says NA means typical\n",
    "    df_processed[\"Functional\"] = df_processed[\"Functional\"].fillna(\"Typ\")    \n",
    "    \n",
    "\n",
    "    # drop GarageArea - higher correlation than GarageACars, results are better as well\n",
    "    df_processed = df_processed.drop(['GarageArea'], axis=1) \n",
    "    df_processed = df_processed.drop(['MiscFeature'], axis=1) \n",
    "#     df_processed = df_processed.drop(['1stFlrSF'], axis=1) \n",
    "    df_processed = df_processed.drop(['TotRmsAbvGrd'], axis=1) \n",
    "\n",
    "    \n",
    "    # Feature Transformation - take the logarithm of the features.\n",
    "    #Linear_Num_Cols = ['TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'LotArea', 'GarageArea', 'TotRmsAbvGrd', 'TotalSF', 'BsmtFinSF1']\n",
    "    df_processed.GrLivArea = np.log(df_processed.GrLivArea)\n",
    "    df_processed.TotalBsmtSF = np.log(df_processed.TotalBsmtSF+1)\n",
    "#     df_processed.LotArea = np.log(df_processed.LotArea) -- performance decreases\n",
    "#     df_processed.GarageArea = np.log(df_processed.GarageArea) -- will drop column \n",
    "\n",
    "\n",
    "\n",
    "    # Categorical Features Processsing\n",
    "\n",
    "    # MSSubClass processing - MSSubClass 20-90 contains only duplicate information with HouseStyle and YearBuilt.\n",
    "    df_processed['MSSubClass'] = df_processed['MSSubClass'].replace(['20','30','40','45','50','60','70','75','80','85'], '0')\n",
    "\n",
    "    # Convert numerical to categorical. \n",
    "    df_processed['MSSubClass'] = df_processed['MSSubClass'].astype(str)\n",
    "\n",
    "    #Encode some categorical features as ordered numbers when there is information in the order.\n",
    "    df_processed = df_processed.replace({\"Alley\" : {\"None\":0,\"Grvl\" : 1, \"Pave\" : 2},\n",
    "                       \"BsmtCond\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"BsmtExposure\" : {\"None\" : 0,\"No\":1, \"Mn\" : 2, \"Av\": 3, \"Gd\" : 4},\n",
    "                       \"BsmtFinType1\" : {\"None\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4,\n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtFinType2\" : {\"None\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4,\n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtQual\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"FireplaceQu\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5,\n",
    "                                       \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n",
    "                       \"GarageCond\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"GarageQual\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"LandSlope\" : {\"Sev\" : 3, \"Mod\" : 2, \"Gtl\" : 1},\n",
    "                       \"LotShape\" : {\"IR3\" : 4, \"IR2\" : 3, \"IR1\" : 2, \"Reg\" : 1},\n",
    "                       \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n",
    "                       \"PoolQC\" : {\"None\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n",
    "                       \"Street\" : {\"Grvl\" : 1, \"Pave\" : 2}})\n",
    "    \n",
    "\n",
    "    \n",
    "    # Year processing \n",
    "    # Combine year sold with year build to year old\n",
    "    df_processed['YearsOld']  = df_processed['YrSold'] - df_processed['YearBuilt']\n",
    "    df_processed = df_processed.drop(['YearBuilt'], axis=1)\n",
    "\n",
    "    # Combine YrSold and YearRemodAdd\n",
    "    df_processed['YearSinceRemodel'] = df_processed['YrSold'] - df_processed['YearRemodAdd']\n",
    "    df_processed = df_processed.drop(['YearRemodAdd'], axis=1)\n",
    "    df_processed = df_processed.drop(['YrSold'], axis=1)\n",
    "    \n",
    "    # Missing rate greater than 47%, and low correlation with sale price\n",
    "    df_processed = df_processed.drop(['FireplaceQu'], axis=1)\n",
    "\n",
    "    # PoolQC has .99 missing value. drop will lower rmse\n",
    "    df_processed = df_processed.drop(['PoolQC'], axis=1)\n",
    "    \n",
    "#     MiscVal is 0 when MiscFeature is missing. drop will lower rmse a little\n",
    "#     df_processed = df_processed.drop(['MiscVal'], axis=1)\n",
    "    \n",
    "    #Get Dummies \n",
    "    #df_processed = pd.get_dummies(df_processed, columns=df_processed.select_dtypes(include=['object']).columns, drop_first=True)\n",
    "\n",
    "    #get label encoder. categorical data change to numerical values\n",
    "    # if label_encode:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    categorical_col=df_processed.select_dtypes(include=['O']).columns.to_list()\n",
    "    \n",
    "    for col in categorical_col: \n",
    "        le.fit(df_processed[col])\n",
    "        df_processed[col] = le.fit_transform(df_processed[col])   \n",
    "        \n",
    "    # Split train and test data sets\n",
    "    df_processed_train = df_processed[df_processed.index <= 1460].copy()\n",
    "    df_processed_test = df_processed[df_processed.index > 1460].copy()\n",
    "    \n",
    "    # take log on price\n",
    "    sale_price_train = np.log(sale_price_train)\n",
    "    df_processed_train['SalePrice'] = sale_price_train    \n",
    "    \n",
    "\n",
    "    \n",
    "    if test is False:\n",
    "        return df_processed_train\n",
    "    if test is True:\n",
    "        return df_processed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed=data_process()\n",
    "test_processed=data_process(True)\n",
    "test_processed_x = test_processed.drop(['SalePrice'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Add MLFLOW\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "#Randomized search CV with Random Forrest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    r2_test = r2_score(actual, pred)\n",
    "    return rmse, r2_test\n",
    "\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train, test = train_test_split(train_processed)\n",
    "\n",
    "# The predicted column is \"SalePrice\" .\n",
    "train_x = train.drop([\"SalePrice\"], axis=1)\n",
    "test_x = test.drop([\"SalePrice\"], axis=1)\n",
    "train_y = train[[\"SalePrice\"]]\n",
    "test_y = test[[\"SalePrice\"]]\n",
    "\n",
    "def random_search_rf(n_estimators,\n",
    "                     max_features, max_depth,\n",
    "                     min_samples_split,min_samples_leaf):\n",
    "\n",
    "    \n",
    "    # Execute random forest\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        rf = RandomForestRegressor(oob_score=True)\n",
    "\n",
    "\n",
    "        # Create the random grid\n",
    "        random_grid = {'n_estimators': n_estimators,\n",
    "                       'max_features': max_features,\n",
    "                       'max_depth': max_depth,\n",
    "                       'min_samples_split': min_samples_split,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                      }\n",
    "        print(random_grid)\n",
    "        \n",
    "        # First create the base model to tune\n",
    "        rf = RandomForestRegressor()\n",
    "\n",
    "        # Random search of parameters, using 3 fold cross validation, \n",
    "        # search across 100 different combinations, and use all available cores\n",
    "        rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "        rf_random.fit(train_x, train_y.values.ravel())\n",
    "\n",
    "        print('random forrest best_params per random search')\n",
    "        print (rf_random.best_params_)\n",
    "\n",
    "\n",
    "        best_n_estimator=rf_random.best_params_.get('n_estimators')\n",
    "        best_max_features=rf_random.best_params_.get(\"max_features\")\n",
    "        best_max_depth=rf_random.best_params_.get('max_depth')\n",
    "        best_min_samples_split=rf_random.best_params_.get('min_samples_split')\n",
    "        best_min_samples_leaf=rf_random.best_params_.get(\"min_samples_leaf\")\n",
    "    \n",
    "\n",
    "        #Train random forest based on the best parameters found\n",
    "        rf = RandomForestRegressor( n_estimators=best_n_estimator,\n",
    "                    max_features=best_max_features,\n",
    "                    max_depth=best_max_depth,\n",
    "                    min_samples_split=best_min_samples_split,\n",
    "                    min_samples_leaf=best_min_samples_leaf,\n",
    "                    oob_score =True)\n",
    "\n",
    "\n",
    "        # Train the model on train.csv data\n",
    "        rf.fit(train_x, train_y.values.ravel())\n",
    "        y_pred_train = rf.predict(train_x)\n",
    "        \n",
    "        # Evaluate Metrics\n",
    "        predicted_qualities = rf.predict(test_x)\n",
    "        (rmse, r2_test) = eval_metrics(test_y, predicted_qualities)\n",
    "        \n",
    "\n",
    "        print (test_x.shape)\n",
    "        print (test_processed_x.shape)\n",
    "        #Predict the sales from test.csv\n",
    "        y_pred_test = rf.predict(test_processed_x)\n",
    "\n",
    "        \n",
    "\n",
    "        mae = mean_absolute_error(train_y['SalePrice'].to_numpy(), y_pred_train)\n",
    "        print ('best model parameter mae:', mae)\n",
    "        \n",
    "        #train r2\n",
    "        r2 = r2_score(train_y['SalePrice'].to_numpy(), y_pred_train)\n",
    "        print ('r2_train:', r2)\n",
    "        \n",
    "        oob = rf.oob_score_\n",
    "        print('Oob score: ',oob)\n",
    "        oob_pred = rf.oob_prediction_\n",
    "        rmse_oob = math.sqrt(sum((train_y['SalePrice'].to_numpy()-oob_pred)**2)/len(train_x))\n",
    "        print('Rmse using oob prediction: ', rmse_oob)\n",
    "        \n",
    "        \n",
    "        # Log parameter, metrics, and model to MLflow\n",
    "        mlflow.log_param(\"model\", 'random_forest')\n",
    "        mlflow.log_param(\"n_estimators\", best_n_estimator)\n",
    "        mlflow.log_param(\"max_features\", best_max_features)\n",
    "        mlflow.log_param(\"max_depth\", best_max_depth)\n",
    "        mlflow.log_param(\"min_samples_split\", best_min_samples_split)\n",
    "        mlflow.log_param(\"min_samples_leaf\", best_min_samples_leaf)\n",
    "        \n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2_train\", r2)\n",
    "        mlflow.log_metric(\"r2_test\", r2_test)\n",
    "        mlflow.log_metric(\"oob\", oob)\n",
    "  \n",
    "        #mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "        mlflow.sklearn.log_model(rf, \"model\")\n",
    "        \n",
    "    #Save Submisssion-------------------------------------------------------------------------------------------------------------------------\n",
    "    file_name = './submissions'+'_rf_rand_'+str(best_n_estimator)+'_'+str(best_max_features)+'_'+str(best_max_depth)+'_'+str(\"best_min_samples_split\")+'_'+str(rmse)+'.csv'\n",
    "    submission = pd.DataFrame({'Id':list(range(1461,2920)),'SalePrice':y_pred_test})\n",
    "    submission.to_csv(file_name,index=False)\n",
    "        \n",
    "    return (rmse, mae, r2, oob, rmse_oob,best_n_estimator,best_max_features, best_max_depth,best_min_samples_split,best_min_samples_leaf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run random_search_rf function with start parameters \n",
    "\n",
    "\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, \n",
    "                                            stop = 2000, \n",
    "                                            num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [int(x) for x in np.linspace(start = 35, stop = 50, num = 2)]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(11,300, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2,3,4,5,6,7,8,9,10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2,3,4, 5,6,7,8,9,10,11,12,13,14,15]\n",
    "\n",
    "\n",
    "random_search_rf(n_estimators,max_features, max_depth,min_samples_split,min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Add MLFLOW, grid search with random forrest\n",
    "# import mlflow\n",
    "# import mlflow.sklearn\n",
    "# import math\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.WARN)\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# #Grid Search with Random Forrest\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# import os\n",
    "# import warnings\n",
    "# import sys\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# def grid_search_rf(n_estimators,max_features, max_depth,min_samples_split,min_samples_leaf):\n",
    "#     # Execute random forest\n",
    "#     with mlflow.start_run():\n",
    "        \n",
    "#         rf = RandomForestRegressor(oob_score=True)\n",
    "\n",
    "\n",
    "#         # Create the random grid\n",
    "#         grid = {'n_estimators': n_estimators,\n",
    "#                        'max_features': max_features,\n",
    "#                        'max_depth': max_depth,\n",
    "#                        'min_samples_split': min_samples_split,\n",
    "#                        'min_samples_leaf': min_samples_leaf,\n",
    "#                       }\n",
    "\n",
    "#         # Use the random grid to search for best hyperparameters\n",
    "#         # First create the base model to tune\n",
    "#         rf = RandomForestRegressor()\n",
    "#         # Random search of parameters, using 3 fold cross validation, \n",
    "#         # search across 100 different combinations, and use all available cores\n",
    "#         rf_grid = GridSearchCV(estimator = rf, param_grid = grid, verbose=2, n_jobs = -1)# Fit the random search model\n",
    "#         rf_grid.fit(train_x, train_y.values.ravel())\n",
    "\n",
    "#         print('random forrest best_params per random search')\n",
    "#         print (rf_grid.best_params_)\n",
    "\n",
    "\n",
    "#         best_n_estimator=rf_grid.best_params_.get('n_estimators')\n",
    "#         best_max_features=rf_grid.best_params_.get(\"max_features\")\n",
    "#         best_max_depth=rf_grid.best_params_.get('max_depth')\n",
    "#         best_min_samples_split=rf_grid.best_params_.get('min_samples_split')\n",
    "#         best_min_samples_leaf=rf_grid.best_params_.get(\"min_samples_leaf\")\n",
    "\n",
    "#         #Train random forest based on the best parameters found\n",
    "#         rf = RandomForestRegressor( n_estimators=best_n_estimator,\n",
    "#                     max_features=best_max_features,\n",
    "#                    max_depth=best_max_depth,\n",
    "#                    min_samples_split=best_min_samples_split,\n",
    "#                    min_samples_leaf=best_min_samples_leaf,\n",
    "#                    oob_score =True)\n",
    "\n",
    "#         # Train the model on train.csv data\n",
    "#         rf.fit(train_x, train_y.values.ravel())\n",
    "#         y_pred_train = rf.predict(train_x)\n",
    "\n",
    "#         y_pred_test = rf.predict(test_processed_x)\n",
    "\n",
    "#         #calculate rsme for train data\n",
    "#         rmse = math.sqrt(sum((train_y['SalePrice'].to_numpy()-y_pred_train)**2)/len(train_x))\n",
    "#         print('best model parameter Rmse: ',rmse)\n",
    "\n",
    "#         mae = mean_absolute_error(train_y['SalePrice'].to_numpy(), y_pred_train)\n",
    "#         print ('best model parameter mae:', mae)\n",
    "\n",
    "#         r2 = r2_score(train_y['SalePrice'].to_numpy(), y_pred_train)\n",
    "#         print ('best model r2 score:', r2)\n",
    "\n",
    "#         oob = rf.oob_score_\n",
    "#         print('best model parameter Oob score: ',oob)\n",
    "#         oob_pred = rf.oob_prediction_\n",
    "#         rmse_oob = math.sqrt(sum((train_y['SalePrice'].to_numpy()-oob_pred)**2)/len(train_x))\n",
    "#         print('Rmse using oob prediction: ', rmse_oob)\n",
    "\n",
    "# #     #Save Submisssion-------------------------------------------------------------------------------------------------------------------------\n",
    "# #     file_name = './submissions'+'_rf_grid_'+str(best_n_estimator)+'_'+str(best_max_features)+'_'+str(best_max_depth)+'_'+str(\"best_min_samples_split\")+'_'+str(rmse)+'.csv'\n",
    "# #     submission = pd.DataFrame({'Id':list(range(1461,2920)),'SalePrice':y_pred_test})\n",
    "# #     submission.to_csv(file_name,index=False)\n",
    "    \n",
    "#     #Return Feature Importance-------------------------------------------------------------------------------------------------------------------------\n",
    "#     features = list(zip(list(train_x.columns.values),list(rf.feature_importances_)))\n",
    "#     featureImportance = pd.DataFrame(features).sort_values(by =1,ascending=False)\n",
    "#     featureImportance = featureImportance.rename(columns = {0:'Feature',1:'Frequency_in_Splits'})\n",
    "#     featureImportance = featureImportance[featureImportance['Frequency_in_Splits']!=0]\n",
    "\n",
    "#     return (rmse, mae, r2, oob, rmse_oob,best_n_estimator,best_max_features, best_max_depth,best_min_samples_split,best_min_samples_leaf, featureImportance)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #Run grid search for random forest\n",
    "\n",
    "# # # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 600, stop = 800, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = [int(x) for x in np.linspace(start = 30, stop = 60, num = 2)]\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [109,110,111]\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [3,4,5,6,7]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf  = [1,4,5,6]\n",
    "\n",
    "# grid_search_rf(n_estimators,max_features, max_depth,min_samples_split,min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## random forrest ONLY\n",
    "# import mlflow\n",
    "# import mlflow.sklearn\n",
    "# import math\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.WARN)\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# import os\n",
    "# import warnings\n",
    "# import sys\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ##Add MLFLOW\n",
    "\n",
    "# import os\n",
    "# import warnings\n",
    "# import sys\n",
    "\n",
    "# import mlflow\n",
    "# import mlflow.sklearn\n",
    "\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.WARN)\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "# def rf(n_estimators,max_features, max_depth, min_samples_split, min_samples_leaf):\n",
    "#     # Execute random forest\n",
    "#     with mlflow.start_run():\n",
    "        \n",
    "#         rf = RandomForestRegressor(n_estimators=n_estimators,max_features=max_features, \n",
    "#                                    max_depth=max_depth,\n",
    "#                                    min_samples_split=min_samples_split,\n",
    "#                                    min_samples_leaf=min_samples_leaf,\n",
    "#                                    oob_score=True)\n",
    "\n",
    "#         # Train the model on train.csv data\n",
    "#         rf.fit(train_x, train_y.values.ravel())\n",
    "#         y_pred_train = rf.predict(train_x)\n",
    "        \n",
    "#         y_pred_train=rf.predict(test_processed_x)\n",
    "        \n",
    "#         # Evaluate Metrics\n",
    "#         predicted_qualities = rf.predict(test_x)\n",
    "#         (rmse, r2_test) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "#         #calculate rsme for train data\n",
    "# #         rmse = math.sqrt(sum((train_y['SalePrice'].to_numpy()-y_pred_train)**2)/len(train_x))\n",
    "#         print('best model parameter Rmse: ',rmse)\n",
    "\n",
    "#         mae = mean_absolute_error(train_y['SalePrice'].to_numpy(), y_pred_train)\n",
    "#         print ('best model parameter mae:', mae)\n",
    "\n",
    "#         r2 = r2_score(train_y['SalePrice'].to_numpy(), y_pred_train)\n",
    "#         print ('best model r2 score:', r2)\n",
    "\n",
    "#         oob = rf.oob_score_\n",
    "#         print('best model parameter Oob score: ',oob)\n",
    "#         oob_pred = rf.oob_prediction_\n",
    "#         rmse_oob = math.sqrt(sum((train_y['SalePrice'].to_numpy()-oob_pred)**2)/len(train_x))\n",
    "#         print('Rmse using oob prediction: ', rmse_oob)\n",
    "        \n",
    "        \n",
    "#         # Log parameter, metrics, and model to MLflow\n",
    "#         mlflow.log_param(\"model\", 'random_forest')\n",
    "#         mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "#         mlflow.log_param(\"max_features\", max_features)\n",
    "#         mlflow.log_param(\"max_depth\", max_depth)\n",
    "#         mlflow.log_param(\"min_samples_split\", min_samples_split)\n",
    "#         mlflow.log_param(\"min_samples_leaf\", min_samples_leaf)\n",
    "        \n",
    "#         mlflow.log_metric(\"rmse\", rmse)\n",
    "#         mlflow.log_metric(\"r2_train\", r2)\n",
    "#         mlflow.log_metric(\"r2_test\", r2_test)\n",
    "#         mlflow.log_metric(\"oob\", oob)\n",
    "  \n",
    "#         #mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "#         mlflow.sklearn.log_model(rf, \"model\")\n",
    "        \n",
    "\n",
    "#     #Save Submisssion-------------------------------------------------------------------------------------------------------------------------\n",
    "#     file_name = './submissions'+'_rf_grid_'+str(n_estimators)+'_'+str(max_features)+'_'+str(max_depth)+'_'+str(rmse)+'.csv'\n",
    "#     submission = pd.DataFrame({'Id':list(range(1461,2920)),'SalePrice':y_pred_test})\n",
    "#     submission.to_csv(file_name,index=False)\n",
    "    \n",
    "#     #Return Feature Importance-------------------------------------------------------------------------------------------------------------------------\n",
    "#     features = list(zip(list(train_x.columns.values),list(rf.feature_importances_)))\n",
    "#     featureImportance = pd.DataFrame(features).sort_values(by =1,ascending=False)\n",
    "#     featureImportance = featureImportance.rename(columns = {0:'Feature',1:'Frequency_in_Splits'})\n",
    "#     featureImportance = featureImportance[featureImportance['Frequency_in_Splits']!=0]\n",
    "\n",
    "#     return (rmse, mae, r2, oob, rmse_oob,featureImportance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest only\n",
    "##Add MLFLOW\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "#Randomized search CV with Random Forrest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    r2_test = r2_score(actual, pred)\n",
    "    return rmse, r2_test\n",
    "\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train, test = train_test_split(train_processed)\n",
    "\n",
    "# The predicted column is \"SalePrice\" .\n",
    "train_x = train.drop([\"SalePrice\"], axis=1)\n",
    "test_x = test.drop([\"SalePrice\"], axis=1)\n",
    "train_y = train[[\"SalePrice\"]]\n",
    "test_y = test[[\"SalePrice\"]]\n",
    "\n",
    "def rf(n_estimators,\n",
    "                     max_features, max_depth,\n",
    "                     min_samples_split,min_samples_leaf):\n",
    "\n",
    "    \n",
    "    # Execute random forest\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        rf = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                                   max_features=max_features, \n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_split=min_samples_split,\n",
    "                                   min_samples_leaf=min_samples_leaf,\n",
    "                                   oob_score=True)\n",
    "\n",
    "\n",
    "        # Train the model on train.csv data\n",
    "        rf.fit(train_x, train_y.values.ravel())\n",
    "        y_pred_train = rf.predict(train_x)\n",
    "        \n",
    "        # Evaluate Metrics\n",
    "        predicted_qualities = rf.predict(test_x)\n",
    "        (rmse, r2_test) = eval_metrics(test_y, predicted_qualities)\n",
    "        \n",
    "        #Predict the sales from test.csv\n",
    "        y_pred_test = rf.predict(test_processed_x)\n",
    "\n",
    "        \n",
    "        #calculate rsme for train data\n",
    "# #         rmse = math.sqrt(sum((train_y['SalePrice'].to_numpy()-y_pred_train)**2)/len(train_x))\n",
    "#         print('Rmse: ',rmse)\n",
    "\n",
    "        mae = mean_absolute_error(train_y['SalePrice'].to_numpy(), y_pred_train)\n",
    "        print ('mae:', mae)\n",
    "\n",
    "        r2 = r2_score(train_y['SalePrice'].to_numpy(), y_pred_train)\n",
    "\n",
    "        oob = rf.oob_score_\n",
    "        oob_pred = rf.oob_prediction_\n",
    "        rmse_oob = math.sqrt(sum((train_y['SalePrice'].to_numpy()-oob_pred)**2)/len(train_x))\n",
    "\n",
    "        \n",
    "        # Log parameter, metrics, and model to MLflow\n",
    "        mlflow.log_param(\"model\", 'random_forest')\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        mlflow.log_param(\"max_features\", max_features)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"min_samples_split\", min_samples_split)\n",
    "        mlflow.log_param(\"min_samples_leaf\", min_samples_leaf)\n",
    "        \n",
    "        \n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2_train\", r2)\n",
    "        mlflow.log_metric(\"r2_test\", r2_test)\n",
    "        mlflow.log_metric(\"oob\" , oob)\n",
    "  \n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "        mlflow.sklearn.log_model(rf, \"model\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"model\", 'random_forest')\n",
    "        print(\"n_estimators\", n_estimators)\n",
    "        print(\"max_features\", max_features)\n",
    "        print(\"max_depth\", max_depth)\n",
    "        print(\"min_samples_split\", min_samples_split)\n",
    "        print(\"min_samples_leaf\", min_samples_leaf)\n",
    "        \n",
    "        \n",
    "        print(\"rmse\", rmse)\n",
    "        print(\"r2_train\", r2)\n",
    "        print(\"r2_test\", r2_test)\n",
    "        print(\"oob\", oob)\n",
    "        print ('oob RMSE', rmse_oob)\n",
    "    #Save Submisssion-------------------------------------------------------------------------------------------------------------------------\n",
    "    file_name = './submissions'+'_rf_grid_'+str(n_estimators)+'_'+str(max_features)+'_'+str(max_depth)+'_'+str(rmse)+'.csv'\n",
    "    submission = pd.DataFrame({'Id':list(range(1461,2920)),'SalePrice':y_pred_test})\n",
    "    submission.to_csv(file_name,index=False)\n",
    "    \n",
    "    #Return Feature Importance-------------------------------------------------------------------------------------------------------------------------\n",
    "    features = list(zip(list(train_x.columns.values),list(rf.feature_importances_)))\n",
    "    featureImportance = pd.DataFrame(features).sort_values(by =1,ascending=False)\n",
    "    featureImportance = featureImportance.rename(columns = {0:'Feature',1:'Feature Importance'})\n",
    "    featureImportance = featureImportance[featureImportance['Feature Importance']!=0]\n",
    "\n",
    "\n",
    "    return (rmse, mae, r2, oob, rmse_oob,n_estimators,max_features, max_depth, min_samples_split,min_samples_leaf,featureImportance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.047700188718317584\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 50\n",
      "min_samples_split 2\n",
      "min_samples_leaf 3\n",
      "rmse 0.1234246257005989\n",
      "r2_train 0.9665074020449539\n",
      "r2_test 0.8885007835858028\n",
      "oob 0.894048970277044\n",
      "oob RMSE 0.13137653865722268\n",
      "mae: 0.04773926748171227\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 50\n",
      "min_samples_split 5\n",
      "min_samples_leaf 3\n",
      "rmse 0.1247437442451505\n",
      "r2_train 0.9662555491890132\n",
      "r2_test 0.8861047194894991\n",
      "oob 0.894026550006355\n",
      "oob RMSE 0.13139043820005414\n",
      "mae: 0.05103069459055487\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 50\n",
      "min_samples_split 8\n",
      "min_samples_leaf 3\n",
      "rmse 0.12386725664557147\n",
      "r2_train 0.9619854477837402\n",
      "r2_test 0.8876996225658658\n",
      "oob 0.8938512455143133\n",
      "oob RMSE 0.1314990683158523\n",
      "mae: 0.05604552455933509\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 50\n",
      "min_samples_split 11\n",
      "min_samples_leaf 3\n",
      "rmse 0.12494727261687302\n",
      "r2_train 0.9554079220219297\n",
      "r2_test 0.8857327596481824\n",
      "oob 0.8920812673348352\n",
      "oob RMSE 0.13259087687570337\n",
      "mae: 0.060200340583118135\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 50\n",
      "min_samples_split 14\n",
      "min_samples_leaf 3\n",
      "rmse 0.1265040877161126\n",
      "r2_train 0.9494971109011207\n",
      "r2_test 0.8828675315455086\n",
      "oob 0.8901519028332074\n",
      "oob RMSE 0.13377085215077114\n",
      "mae: 0.0636527962545219\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 50\n",
      "min_samples_split 17\n",
      "min_samples_leaf 3\n",
      "rmse 0.12725436982628052\n",
      "r2_train 0.9432871121648381\n",
      "r2_test 0.8814740112616839\n",
      "oob 0.8872997796640198\n",
      "oob RMSE 0.13549635333794868\n",
      "mae: 0.0477023131240125\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 54\n",
      "min_samples_split 2\n",
      "min_samples_leaf 3\n",
      "rmse 0.12399602080834071\n",
      "r2_train 0.9664550155632552\n",
      "r2_test 0.887466021202031\n",
      "oob 0.8942068788771043\n",
      "oob RMSE 0.13127860086063917\n",
      "mae: 0.04772403204047685\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 54\n",
      "min_samples_split 5\n",
      "min_samples_leaf 3\n",
      "rmse 0.12365230802882045\n",
      "r2_train 0.966333739660408\n",
      "r2_test 0.888089037286623\n",
      "oob 0.8945933719520326\n",
      "oob RMSE 0.131038581968864\n",
      "mae: 0.05088856026212563\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 54\n",
      "min_samples_split 8\n",
      "min_samples_leaf 3\n",
      "rmse 0.1242695872333507\n",
      "r2_train 0.9622592031849141\n",
      "r2_test 0.8869689168857606\n",
      "oob 0.8941250544395759\n",
      "oob RMSE 0.1313293589880803\n",
      "mae: 0.05590962569449861\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 54\n",
      "min_samples_split 11\n",
      "min_samples_leaf 3\n",
      "rmse 0.1256386309895105\n",
      "r2_train 0.9553193278829217\n",
      "r2_test 0.8844647339915087\n",
      "oob 0.8921406109725866\n",
      "oob RMSE 0.13255441653760733\n",
      "mae: 0.060351600759873475\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 54\n",
      "min_samples_split 14\n",
      "min_samples_leaf 3\n",
      "rmse 0.12607683811627649\n",
      "r2_train 0.9493336141462329\n",
      "r2_test 0.8836573920404898\n",
      "oob 0.8900078633911296\n",
      "oob RMSE 0.13385852761858857\n",
      "mae: 0.06375589462883309\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 54\n",
      "min_samples_split 17\n",
      "min_samples_leaf 3\n",
      "rmse 0.12743040204656386\n",
      "r2_train 0.9439237458280239\n",
      "r2_test 0.8811458681268384\n",
      "oob 0.8870730306224205\n",
      "oob RMSE 0.13563259189164756\n",
      "mae: 0.047752198363865586\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 58\n",
      "min_samples_split 2\n",
      "min_samples_leaf 3\n",
      "rmse 0.12445891924307995\n",
      "r2_train 0.966390210228023\n",
      "r2_test 0.8866242355363004\n",
      "oob 0.8934319119872218\n",
      "oob RMSE 0.131758551420648\n",
      "mae: 0.047719237506303316\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 58\n",
      "min_samples_split 5\n",
      "min_samples_leaf 3\n",
      "rmse 0.12331854186466053\n",
      "r2_train 0.9663029880103794\n",
      "r2_test 0.8886923690380542\n",
      "oob 0.8941764904306915\n",
      "oob RMSE 0.13129745400650902\n",
      "mae: 0.050912027981336386\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 58\n",
      "min_samples_split 8\n",
      "min_samples_leaf 3\n",
      "rmse 0.12425988640483424\n",
      "r2_train 0.9620735616435224\n",
      "r2_test 0.8869865632364247\n",
      "oob 0.8936023692291777\n",
      "oob RMSE 0.13165313436830228\n",
      "mae: 0.05607162205711461\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 58\n",
      "min_samples_split 11\n",
      "min_samples_leaf 3\n",
      "rmse 0.12515038272765563\n",
      "r2_train 0.9552765500754579\n",
      "r2_test 0.8853609596863117\n",
      "oob 0.8925292162337078\n",
      "oob RMSE 0.13231541173105635\n",
      "mae: 0.05999100369042328\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 58\n",
      "min_samples_split 14\n",
      "min_samples_leaf 3\n",
      "rmse 0.12688287753206975\n",
      "r2_train 0.9494618995713906\n",
      "r2_test 0.8821650244066712\n",
      "oob 0.8904064948586755\n",
      "oob RMSE 0.13361574364536877\n",
      "mae: 0.06357120759758624\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 58\n",
      "min_samples_split 17\n",
      "min_samples_leaf 3\n",
      "rmse 0.12752741035421997\n",
      "r2_train 0.9439961025979706\n",
      "r2_test 0.8809648402616357\n",
      "oob 0.8875090552625786\n",
      "oob RMSE 0.13537049175417587\n",
      "mae: 0.0476042429783868\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 62\n",
      "min_samples_split 2\n",
      "min_samples_leaf 3\n",
      "rmse 0.12416535689626063\n",
      "r2_train 0.966250351192012\n",
      "r2_test 0.8871584455938628\n",
      "oob 0.8949697036511063\n",
      "oob RMSE 0.13080445026341536\n",
      "mae: 0.047550882301100814\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 62\n",
      "min_samples_split 5\n",
      "min_samples_leaf 3\n",
      "rmse 0.12384049779866492\n",
      "r2_train 0.9669184912456802\n",
      "r2_test 0.8877481374696894\n",
      "oob 0.8950269130761898\n",
      "oob RMSE 0.130768821178491\n",
      "mae: 0.051243128982031066\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 62\n",
      "min_samples_split 8\n",
      "min_samples_leaf 3\n",
      "rmse 0.12480342846368425\n",
      "r2_train 0.9617969076382262\n",
      "r2_test 0.8859957059744619\n",
      "oob 0.8933698047788955\n",
      "oob RMSE 0.13179693985394383\n",
      "mae: 0.05625749718613519\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 62\n",
      "min_samples_split 11\n",
      "min_samples_leaf 3\n",
      "rmse 0.1260328079770327\n",
      "r2_train 0.9552990103585789\n",
      "r2_test 0.8837386391088465\n",
      "oob 0.8915177699199314\n",
      "oob RMSE 0.1329365876608791\n",
      "mae: 0.060205015824723866\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 62\n",
      "min_samples_split 14\n",
      "min_samples_leaf 3\n",
      "rmse 0.12681944609725693\n",
      "r2_train 0.9500005825330168\n",
      "r2_test 0.8822828113516497\n",
      "oob 0.8910857252229208\n",
      "oob RMSE 0.13320104330551802\n",
      "mae: 0.06355018360418302\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 62\n",
      "min_samples_split 17\n",
      "min_samples_leaf 3\n",
      "rmse 0.1275348638108206\n",
      "r2_train 0.9442709607325449\n",
      "r2_test 0.8809509256165897\n",
      "oob 0.8880523620751924\n",
      "oob RMSE 0.13504319105216714\n",
      "mae: 0.04774801847681149\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 66\n",
      "min_samples_split 2\n",
      "min_samples_leaf 3\n",
      "rmse 0.1243628323373797\n",
      "r2_train 0.9666579834553984\n",
      "r2_test 0.8867992285572452\n",
      "oob 0.8942207555846376\n",
      "oob RMSE 0.13126999078055115\n",
      "mae: 0.04769149175211088\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 66\n",
      "min_samples_split 5\n",
      "min_samples_leaf 3\n",
      "rmse 0.12472787473709512\n",
      "r2_train 0.966716222995656\n",
      "r2_test 0.8861336964472237\n",
      "oob 0.8952236966725187\n",
      "oob RMSE 0.13064619341312828\n",
      "mae: 0.05123157515921099\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 66\n",
      "min_samples_split 8\n",
      "min_samples_leaf 3\n",
      "rmse 0.12469565718658598\n",
      "r2_train 0.9618699097910727\n",
      "r2_test 0.8861925128040775\n",
      "oob 0.8934288256709918\n",
      "oob RMSE 0.13176045933519864\n",
      "mae: 0.05600955197460667\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 66\n",
      "min_samples_split 11\n",
      "min_samples_leaf 3\n",
      "rmse 0.12593706699289073\n",
      "r2_train 0.9553530999260592\n",
      "r2_test 0.8839152082015691\n",
      "oob 0.8916568284766382\n",
      "oob RMSE 0.13285135758270822\n",
      "mae: 0.0602884305716309\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 66\n",
      "min_samples_split 14\n",
      "min_samples_leaf 3\n",
      "rmse 0.12661323111931988\n",
      "r2_train 0.9494589924994271\n",
      "r2_test 0.8826653285753889\n",
      "oob 0.8900024658590839\n",
      "oob RMSE 0.1338618119298639\n",
      "mae: 0.06375790616591538\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 66\n",
      "min_samples_split 17\n",
      "min_samples_leaf 3\n",
      "rmse 0.1275033495488823\n",
      "r2_train 0.9436767830317804\n",
      "r2_test 0.8810097531413585\n",
      "oob 0.8880705971535303\n",
      "oob RMSE 0.13503219205521935\n",
      "mae: 0.0475835542603278\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 70\n",
      "min_samples_split 2\n",
      "min_samples_leaf 3\n",
      "rmse 0.12357948504473487\n",
      "r2_train 0.9669534048487258\n",
      "r2_test 0.8882208146965854\n",
      "oob 0.8953029221294193\n",
      "oob RMSE 0.13059679072672886\n",
      "mae: 0.04777004980429894\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 70\n",
      "min_samples_split 5\n",
      "min_samples_leaf 3\n",
      "rmse 0.12432854822640411\n",
      "r2_train 0.9661927969040228\n",
      "r2_test 0.8868616339043418\n",
      "oob 0.8943253612651739\n",
      "oob RMSE 0.13120506791555223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.05074742537105189\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 70\n",
      "min_samples_split 8\n",
      "min_samples_leaf 3\n",
      "rmse 0.12484399933256157\n",
      "r2_train 0.9622321371142742\n",
      "r2_test 0.885921573314715\n",
      "oob 0.8937591045830845\n",
      "oob RMSE 0.13155612889292587\n",
      "mae: 0.05582631429445602\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 70\n",
      "min_samples_split 11\n",
      "min_samples_leaf 3\n",
      "rmse 0.12602792948757038\n",
      "r2_train 0.955780417336686\n",
      "r2_test 0.8837476394454392\n",
      "oob 0.8924617758712647\n",
      "oob RMSE 0.13235692068605473\n",
      "mae: 0.06024901811463556\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 70\n",
      "min_samples_split 14\n",
      "min_samples_leaf 3\n",
      "rmse 0.1264841356205769\n",
      "r2_train 0.9492938746882514\n",
      "r2_test 0.8829044766584371\n",
      "oob 0.8897805995977404\n",
      "oob RMSE 0.13399674431289413\n",
      "mae: 0.06344266890555615\n",
      "model random_forest\n",
      "n_estimators 700\n",
      "max_features 25\n",
      "max_depth 70\n",
      "min_samples_split 17\n",
      "min_samples_leaf 3\n",
      "rmse 0.12742546697336113\n",
      "r2_train 0.9442799027857542\n",
      "r2_test 0.8811550738183204\n",
      "oob 0.8882673663696209\n",
      "oob RMSE 0.13491344816124645\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-11c5a4d494a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmin_samples_split1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mmin_samples_leaf1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                     \u001b[0mrmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse_oob\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatureImportance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_estimators1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_features1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_depth1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_samples_split1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_samples_leaf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m                     \u001b[0mrmseL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                     \u001b[0mmaeL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmae\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-6fb8bc0f62cf>\u001b[0m in \u001b[0;36mrf\u001b[1;34m(n_estimators, max_features, max_depth, min_samples_split, min_samples_leaf)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;31m# Train the model on train.csv data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0my_pred_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 330\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1155\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1158\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rmseL=[]\n",
    "maeL=[]\n",
    "r2L=[]\n",
    "oobL=[]\n",
    "rmse_oobL=[]\n",
    "n_estimatorsL=[]\n",
    "max_featuresL=[]\n",
    "max_depthL=[]\n",
    "min_samples_splitL=[]\n",
    "min_samples_leafL=[]\n",
    "featureImportanceL=[]\n",
    "# n_estimators1=800\n",
    "# max_features1=35\n",
    "# max_depth1=68\n",
    "# min_samples_split1=2\n",
    "# min_samples_leaf1=5\n",
    "\n",
    "\n",
    "for n_estimators1 in range (700,800,10):\n",
    "    for max_features1 in range (25, 41,5):\n",
    "        for max_depth1 in range (50,100,4):\n",
    "            for min_samples_split1 in range (2,20,3):\n",
    "                for min_samples_leaf1 in range(3,10,10):\n",
    "                    rmse, mae, r2, oob, rmse_oob,n_estimators,max_features, max_depth, min_samples_split,min_samples_leaf,featureImportance=rf(n_estimators=n_estimators1,max_features=max_features1, max_depth=max_depth1,min_samples_split=min_samples_split1,min_samples_leaf=min_samples_leaf1)\n",
    "                    rmseL.append(rmse)\n",
    "                    maeL.append(mae)\n",
    "                    r2L.append(r2)\n",
    "                    oobL.append(oob)\n",
    "                    rmse_oobL.append(rmse_oob)\n",
    "                    n_estimatorsL.append(n_estimators)\n",
    "                    max_featuresL.append(max_features)\n",
    "                    max_depthL.append(max_depth)\n",
    "                    min_samples_splitL.append(min_samples_split)\n",
    "                    min_samples_leafL.append(min_samples_leaf)\n",
    "                    featureImportanceL.append(featureImportance)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmseL</th>\n",
       "      <th>maeL</th>\n",
       "      <th>r2L</th>\n",
       "      <th>oobL</th>\n",
       "      <th>rmse_oobL</th>\n",
       "      <th>n_estimatorsL</th>\n",
       "      <th>max_featuresL</th>\n",
       "      <th>max_depthL</th>\n",
       "      <th>min_samples_splitL</th>\n",
       "      <th>min_samples_leafL</th>\n",
       "      <th>featureImportanceL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.159175</td>\n",
       "      <td>0.046570</td>\n",
       "      <td>0.966773</td>\n",
       "      <td>0.893749</td>\n",
       "      <td>0.124011</td>\n",
       "      <td>700</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.159335</td>\n",
       "      <td>0.046475</td>\n",
       "      <td>0.966972</td>\n",
       "      <td>0.893598</td>\n",
       "      <td>0.124099</td>\n",
       "      <td>700</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.160027</td>\n",
       "      <td>0.049568</td>\n",
       "      <td>0.962993</td>\n",
       "      <td>0.893905</td>\n",
       "      <td>0.123919</td>\n",
       "      <td>700</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.161472</td>\n",
       "      <td>0.054733</td>\n",
       "      <td>0.956239</td>\n",
       "      <td>0.891392</td>\n",
       "      <td>0.125378</td>\n",
       "      <td>700</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.164366</td>\n",
       "      <td>0.058875</td>\n",
       "      <td>0.950256</td>\n",
       "      <td>0.889764</td>\n",
       "      <td>0.126315</td>\n",
       "      <td>700</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rmseL      maeL       r2L      oobL  rmse_oobL  n_estimatorsL  \\\n",
       "0  0.159175  0.046570  0.966773  0.893749   0.124011            700   \n",
       "1  0.159335  0.046475  0.966972  0.893598   0.124099            700   \n",
       "2  0.160027  0.049568  0.962993  0.893905   0.123919            700   \n",
       "3  0.161472  0.054733  0.956239  0.891392   0.125378            700   \n",
       "4  0.164366  0.058875  0.950256  0.889764   0.126315            700   \n",
       "\n",
       "   max_featuresL  max_depthL  min_samples_splitL  min_samples_leafL  \\\n",
       "0             25          50                   2                  3   \n",
       "1             25          50                   5                  3   \n",
       "2             25          50                   8                  3   \n",
       "3             25          50                  11                  3   \n",
       "4             25          50                  14                  3   \n",
       "\n",
       "                                  featureImportanceL  \n",
       "0               Feature  Feature Importance\n",
       "55   ...  \n",
       "1               Feature  Feature Importance\n",
       "55   ...  \n",
       "2               Feature  Feature Importance\n",
       "55   ...  \n",
       "3               Feature  Feature Importance\n",
       "55   ...  \n",
       "4               Feature  Feature Importance\n",
       "55   ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result_d={\"rmse\":rmseL}, {\"mae\":maeL}, {\"r2\":r2L}, \n",
    "#             {\"oob\":oobL}, \"rmse_oob\":rmse_oobL,\n",
    "#             \"n_estimators\"=n_estimatorsL,\n",
    "#             \"max_features\"=max_featuresL, \n",
    "#             \"max_depth\"=max_depthL, min_samples_split=min_samples_splitL,\n",
    "#             \"min_samples_leaf\"=min_samples_leafL,\n",
    "#             \"featureImportance\"=featureImportanceL}\n",
    "\n",
    "\n",
    "result=pd.DataFrame(list(zip(rmseL,maeL,r2L,oobL,rmse_oobL,n_estimatorsL,max_featuresL,max_depthL,min_samples_splitL,min_samples_leafL,featureImportanceL\n",
    ")),columns=[\"rmseL\",\"maeL\",\"r2L\",\"oobL\",\"rmse_oobL\",\"n_estimatorsL\",\"max_featuresL\",\"max_depthL\",\"min_samples_splitL\",\"min_samples_leafL\",\"featureImportanceL\"\n",
    "])\n",
    "\n",
    "result=pd.DataFrame(result)\n",
    "\n",
    "result.to_csv('result_random_forrest_new',index=False)\n",
    "result.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmseL</th>\n",
       "      <th>maeL</th>\n",
       "      <th>r2L</th>\n",
       "      <th>oobL</th>\n",
       "      <th>rmse_oobL</th>\n",
       "      <th>n_estimatorsL</th>\n",
       "      <th>max_featuresL</th>\n",
       "      <th>max_depthL</th>\n",
       "      <th>min_samples_splitL</th>\n",
       "      <th>min_samples_leafL</th>\n",
       "      <th>featureImportanceL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0.159177</td>\n",
       "      <td>0.044834</td>\n",
       "      <td>0.969458</td>\n",
       "      <td>0.895827</td>\n",
       "      <td>0.122792</td>\n",
       "      <td>710</td>\n",
       "      <td>35</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.158707</td>\n",
       "      <td>0.045677</td>\n",
       "      <td>0.968438</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.122798</td>\n",
       "      <td>700</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>0.159709</td>\n",
       "      <td>0.044436</td>\n",
       "      <td>0.970012</td>\n",
       "      <td>0.895787</td>\n",
       "      <td>0.122815</td>\n",
       "      <td>790</td>\n",
       "      <td>40</td>\n",
       "      <td>94</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>0.159292</td>\n",
       "      <td>0.044883</td>\n",
       "      <td>0.969280</td>\n",
       "      <td>0.895758</td>\n",
       "      <td>0.122833</td>\n",
       "      <td>790</td>\n",
       "      <td>35</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>0.159874</td>\n",
       "      <td>0.044394</td>\n",
       "      <td>0.969985</td>\n",
       "      <td>0.895723</td>\n",
       "      <td>0.122853</td>\n",
       "      <td>750</td>\n",
       "      <td>40</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>0.159326</td>\n",
       "      <td>0.044926</td>\n",
       "      <td>0.969272</td>\n",
       "      <td>0.895658</td>\n",
       "      <td>0.122891</td>\n",
       "      <td>750</td>\n",
       "      <td>35</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>0.159609</td>\n",
       "      <td>0.045133</td>\n",
       "      <td>0.969070</td>\n",
       "      <td>0.895648</td>\n",
       "      <td>0.122897</td>\n",
       "      <td>750</td>\n",
       "      <td>35</td>\n",
       "      <td>86</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.159781</td>\n",
       "      <td>0.045532</td>\n",
       "      <td>0.968659</td>\n",
       "      <td>0.895644</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>700</td>\n",
       "      <td>30</td>\n",
       "      <td>94</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>0.159626</td>\n",
       "      <td>0.046327</td>\n",
       "      <td>0.967165</td>\n",
       "      <td>0.895641</td>\n",
       "      <td>0.122901</td>\n",
       "      <td>740</td>\n",
       "      <td>25</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>0.160252</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>0.970187</td>\n",
       "      <td>0.895592</td>\n",
       "      <td>0.122930</td>\n",
       "      <td>780</td>\n",
       "      <td>40</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>0.158406</td>\n",
       "      <td>0.045650</td>\n",
       "      <td>0.968437</td>\n",
       "      <td>0.895582</td>\n",
       "      <td>0.122936</td>\n",
       "      <td>770</td>\n",
       "      <td>30</td>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>0.158687</td>\n",
       "      <td>0.045029</td>\n",
       "      <td>0.969034</td>\n",
       "      <td>0.895580</td>\n",
       "      <td>0.122937</td>\n",
       "      <td>780</td>\n",
       "      <td>35</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>0.159675</td>\n",
       "      <td>0.044911</td>\n",
       "      <td>0.969214</td>\n",
       "      <td>0.895570</td>\n",
       "      <td>0.122943</td>\n",
       "      <td>780</td>\n",
       "      <td>35</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0.159005</td>\n",
       "      <td>0.046418</td>\n",
       "      <td>0.967280</td>\n",
       "      <td>0.895563</td>\n",
       "      <td>0.122947</td>\n",
       "      <td>710</td>\n",
       "      <td>25</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>0.159492</td>\n",
       "      <td>0.044875</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.895559</td>\n",
       "      <td>0.122949</td>\n",
       "      <td>780</td>\n",
       "      <td>35</td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.159661</td>\n",
       "      <td>0.044894</td>\n",
       "      <td>0.969302</td>\n",
       "      <td>0.895559</td>\n",
       "      <td>0.122949</td>\n",
       "      <td>700</td>\n",
       "      <td>35</td>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>0.159852</td>\n",
       "      <td>0.045604</td>\n",
       "      <td>0.968452</td>\n",
       "      <td>0.895554</td>\n",
       "      <td>0.122952</td>\n",
       "      <td>740</td>\n",
       "      <td>30</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>0.159366</td>\n",
       "      <td>0.045470</td>\n",
       "      <td>0.968277</td>\n",
       "      <td>0.895506</td>\n",
       "      <td>0.122981</td>\n",
       "      <td>780</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>0.159367</td>\n",
       "      <td>0.044952</td>\n",
       "      <td>0.969251</td>\n",
       "      <td>0.895491</td>\n",
       "      <td>0.122990</td>\n",
       "      <td>730</td>\n",
       "      <td>35</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>0.158804</td>\n",
       "      <td>0.045699</td>\n",
       "      <td>0.968567</td>\n",
       "      <td>0.895487</td>\n",
       "      <td>0.122992</td>\n",
       "      <td>750</td>\n",
       "      <td>30</td>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>0.159528</td>\n",
       "      <td>0.044987</td>\n",
       "      <td>0.969232</td>\n",
       "      <td>0.895468</td>\n",
       "      <td>0.123003</td>\n",
       "      <td>710</td>\n",
       "      <td>35</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2953</th>\n",
       "      <td>0.159186</td>\n",
       "      <td>0.045724</td>\n",
       "      <td>0.968269</td>\n",
       "      <td>0.895456</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>790</td>\n",
       "      <td>30</td>\n",
       "      <td>94</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>0.160052</td>\n",
       "      <td>0.044925</td>\n",
       "      <td>0.969287</td>\n",
       "      <td>0.895449</td>\n",
       "      <td>0.123014</td>\n",
       "      <td>730</td>\n",
       "      <td>35</td>\n",
       "      <td>78</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>0.158696</td>\n",
       "      <td>0.046345</td>\n",
       "      <td>0.967227</td>\n",
       "      <td>0.895446</td>\n",
       "      <td>0.123016</td>\n",
       "      <td>780</td>\n",
       "      <td>25</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>0.159141</td>\n",
       "      <td>0.044918</td>\n",
       "      <td>0.969539</td>\n",
       "      <td>0.895442</td>\n",
       "      <td>0.123018</td>\n",
       "      <td>730</td>\n",
       "      <td>35</td>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>0.159595</td>\n",
       "      <td>0.045109</td>\n",
       "      <td>0.969172</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.123028</td>\n",
       "      <td>760</td>\n",
       "      <td>35</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0.159761</td>\n",
       "      <td>0.046461</td>\n",
       "      <td>0.967077</td>\n",
       "      <td>0.895423</td>\n",
       "      <td>0.123029</td>\n",
       "      <td>710</td>\n",
       "      <td>25</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.159278</td>\n",
       "      <td>0.045021</td>\n",
       "      <td>0.969227</td>\n",
       "      <td>0.895421</td>\n",
       "      <td>0.123031</td>\n",
       "      <td>700</td>\n",
       "      <td>35</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>0.159693</td>\n",
       "      <td>0.044960</td>\n",
       "      <td>0.969387</td>\n",
       "      <td>0.895419</td>\n",
       "      <td>0.123032</td>\n",
       "      <td>740</td>\n",
       "      <td>35</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.159375</td>\n",
       "      <td>0.045632</td>\n",
       "      <td>0.968444</td>\n",
       "      <td>0.895410</td>\n",
       "      <td>0.123037</td>\n",
       "      <td>710</td>\n",
       "      <td>30</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.165126</td>\n",
       "      <td>0.062268</td>\n",
       "      <td>0.944962</td>\n",
       "      <td>0.887039</td>\n",
       "      <td>0.127866</td>\n",
       "      <td>700</td>\n",
       "      <td>25</td>\n",
       "      <td>98</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>0.165644</td>\n",
       "      <td>0.062315</td>\n",
       "      <td>0.944806</td>\n",
       "      <td>0.887010</td>\n",
       "      <td>0.127883</td>\n",
       "      <td>740</td>\n",
       "      <td>25</td>\n",
       "      <td>82</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>0.166118</td>\n",
       "      <td>0.060667</td>\n",
       "      <td>0.948025</td>\n",
       "      <td>0.886997</td>\n",
       "      <td>0.127890</td>\n",
       "      <td>730</td>\n",
       "      <td>40</td>\n",
       "      <td>98</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>0.166294</td>\n",
       "      <td>0.061018</td>\n",
       "      <td>0.948138</td>\n",
       "      <td>0.886979</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>750</td>\n",
       "      <td>40</td>\n",
       "      <td>74</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>0.166764</td>\n",
       "      <td>0.061154</td>\n",
       "      <td>0.947697</td>\n",
       "      <td>0.886975</td>\n",
       "      <td>0.127902</td>\n",
       "      <td>780</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.166072</td>\n",
       "      <td>0.060873</td>\n",
       "      <td>0.948096</td>\n",
       "      <td>0.886969</td>\n",
       "      <td>0.127906</td>\n",
       "      <td>700</td>\n",
       "      <td>40</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>0.165907</td>\n",
       "      <td>0.062495</td>\n",
       "      <td>0.944632</td>\n",
       "      <td>0.886958</td>\n",
       "      <td>0.127912</td>\n",
       "      <td>760</td>\n",
       "      <td>25</td>\n",
       "      <td>78</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>0.165864</td>\n",
       "      <td>0.061490</td>\n",
       "      <td>0.946819</td>\n",
       "      <td>0.886957</td>\n",
       "      <td>0.127912</td>\n",
       "      <td>770</td>\n",
       "      <td>35</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>0.165593</td>\n",
       "      <td>0.061286</td>\n",
       "      <td>0.946898</td>\n",
       "      <td>0.886934</td>\n",
       "      <td>0.127925</td>\n",
       "      <td>770</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.165875</td>\n",
       "      <td>0.061305</td>\n",
       "      <td>0.947137</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.127942</td>\n",
       "      <td>700</td>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.166164</td>\n",
       "      <td>0.061023</td>\n",
       "      <td>0.947874</td>\n",
       "      <td>0.886904</td>\n",
       "      <td>0.127943</td>\n",
       "      <td>700</td>\n",
       "      <td>40</td>\n",
       "      <td>78</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>0.166337</td>\n",
       "      <td>0.060977</td>\n",
       "      <td>0.948051</td>\n",
       "      <td>0.886902</td>\n",
       "      <td>0.127944</td>\n",
       "      <td>770</td>\n",
       "      <td>40</td>\n",
       "      <td>90</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>0.165285</td>\n",
       "      <td>0.062135</td>\n",
       "      <td>0.945217</td>\n",
       "      <td>0.886888</td>\n",
       "      <td>0.127952</td>\n",
       "      <td>740</td>\n",
       "      <td>25</td>\n",
       "      <td>94</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>0.164885</td>\n",
       "      <td>0.061243</td>\n",
       "      <td>0.947071</td>\n",
       "      <td>0.886887</td>\n",
       "      <td>0.127952</td>\n",
       "      <td>750</td>\n",
       "      <td>35</td>\n",
       "      <td>78</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>0.165834</td>\n",
       "      <td>0.062274</td>\n",
       "      <td>0.944786</td>\n",
       "      <td>0.886877</td>\n",
       "      <td>0.127958</td>\n",
       "      <td>720</td>\n",
       "      <td>25</td>\n",
       "      <td>82</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>0.166020</td>\n",
       "      <td>0.062412</td>\n",
       "      <td>0.944864</td>\n",
       "      <td>0.886864</td>\n",
       "      <td>0.127965</td>\n",
       "      <td>750</td>\n",
       "      <td>25</td>\n",
       "      <td>94</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>0.166156</td>\n",
       "      <td>0.060825</td>\n",
       "      <td>0.947621</td>\n",
       "      <td>0.886848</td>\n",
       "      <td>0.127974</td>\n",
       "      <td>770</td>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>0.165657</td>\n",
       "      <td>0.061787</td>\n",
       "      <td>0.946065</td>\n",
       "      <td>0.886841</td>\n",
       "      <td>0.127978</td>\n",
       "      <td>770</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>0.165126</td>\n",
       "      <td>0.062457</td>\n",
       "      <td>0.944634</td>\n",
       "      <td>0.886826</td>\n",
       "      <td>0.127987</td>\n",
       "      <td>790</td>\n",
       "      <td>25</td>\n",
       "      <td>70</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>0.166748</td>\n",
       "      <td>0.060859</td>\n",
       "      <td>0.947885</td>\n",
       "      <td>0.886777</td>\n",
       "      <td>0.128014</td>\n",
       "      <td>790</td>\n",
       "      <td>40</td>\n",
       "      <td>78</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>0.165558</td>\n",
       "      <td>0.062425</td>\n",
       "      <td>0.944848</td>\n",
       "      <td>0.886757</td>\n",
       "      <td>0.128026</td>\n",
       "      <td>760</td>\n",
       "      <td>25</td>\n",
       "      <td>74</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>0.166189</td>\n",
       "      <td>0.062512</td>\n",
       "      <td>0.944390</td>\n",
       "      <td>0.886750</td>\n",
       "      <td>0.128029</td>\n",
       "      <td>790</td>\n",
       "      <td>25</td>\n",
       "      <td>90</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>0.165835</td>\n",
       "      <td>0.062289</td>\n",
       "      <td>0.944962</td>\n",
       "      <td>0.886737</td>\n",
       "      <td>0.128037</td>\n",
       "      <td>780</td>\n",
       "      <td>25</td>\n",
       "      <td>66</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0.165960</td>\n",
       "      <td>0.060727</td>\n",
       "      <td>0.948173</td>\n",
       "      <td>0.886688</td>\n",
       "      <td>0.128065</td>\n",
       "      <td>710</td>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>0.165831</td>\n",
       "      <td>0.060915</td>\n",
       "      <td>0.947850</td>\n",
       "      <td>0.886605</td>\n",
       "      <td>0.128112</td>\n",
       "      <td>760</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.165722</td>\n",
       "      <td>0.062437</td>\n",
       "      <td>0.944509</td>\n",
       "      <td>0.886581</td>\n",
       "      <td>0.128125</td>\n",
       "      <td>700</td>\n",
       "      <td>25</td>\n",
       "      <td>62</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>0.165031</td>\n",
       "      <td>0.062345</td>\n",
       "      <td>0.944594</td>\n",
       "      <td>0.886541</td>\n",
       "      <td>0.128148</td>\n",
       "      <td>780</td>\n",
       "      <td>25</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>0.166350</td>\n",
       "      <td>0.062273</td>\n",
       "      <td>0.944955</td>\n",
       "      <td>0.886530</td>\n",
       "      <td>0.128154</td>\n",
       "      <td>710</td>\n",
       "      <td>25</td>\n",
       "      <td>82</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>0.166476</td>\n",
       "      <td>0.061003</td>\n",
       "      <td>0.947385</td>\n",
       "      <td>0.886527</td>\n",
       "      <td>0.128156</td>\n",
       "      <td>730</td>\n",
       "      <td>40</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>0.166128</td>\n",
       "      <td>0.061385</td>\n",
       "      <td>0.946853</td>\n",
       "      <td>0.886436</td>\n",
       "      <td>0.128207</td>\n",
       "      <td>780</td>\n",
       "      <td>35</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Feature  Feature Importance\n",
       "55   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3120 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rmseL      maeL       r2L      oobL  rmse_oobL  n_estimatorsL  \\\n",
       "516   0.159177  0.044834  0.969458  0.895827   0.122792            710   \n",
       "109   0.158707  0.045677  0.968438  0.895817   0.122798            700   \n",
       "3109  0.159709  0.044436  0.970012  0.895787   0.122815            790   \n",
       "2983  0.159292  0.044883  0.969280  0.895758   0.122833            790   \n",
       "1836  0.159874  0.044394  0.969985  0.895723   0.122853            750   \n",
       "1752  0.159326  0.044926  0.969272  0.895658   0.122891            750   \n",
       "1771  0.159609  0.045133  0.969070  0.895648   0.122897            750   \n",
       "145   0.159781  0.045532  0.968659  0.895644   0.122900            700   \n",
       "1254  0.159626  0.046327  0.967165  0.895641   0.122901            740   \n",
       "2772  0.160252  0.044485  0.970187  0.895592   0.122930            780   \n",
       "2311  0.158406  0.045650  0.968437  0.895582   0.122936            770   \n",
       "2694  0.158687  0.045029  0.969034  0.895580   0.122937            780   \n",
       "2652  0.159675  0.044911  0.969214  0.895570   0.122943            780   \n",
       "372   0.159005  0.046418  0.967280  0.895563   0.122947            710   \n",
       "2725  0.159492  0.044875  0.969343  0.895559   0.122949            780   \n",
       "205   0.159661  0.044894  0.969302  0.895559   0.122949            700   \n",
       "1338  0.159852  0.045604  0.968452  0.895554   0.122952            740   \n",
       "2605  0.159366  0.045470  0.968277  0.895506   0.122981            780   \n",
       "1164  0.159367  0.044952  0.969251  0.895491   0.122990            730   \n",
       "1699  0.158804  0.045699  0.968567  0.895487   0.122992            750   \n",
       "540   0.159528  0.044987  0.969232  0.895468   0.123003            710   \n",
       "2953  0.159186  0.045724  0.968269  0.895456   0.123010            790   \n",
       "1135  0.160052  0.044925  0.969287  0.895449   0.123014            730   \n",
       "2503  0.158696  0.046345  0.967227  0.895446   0.123016            780   \n",
       "1153  0.159141  0.044918  0.969539  0.895442   0.123018            730   \n",
       "2100  0.159595  0.045109  0.969172  0.895425   0.123028            760   \n",
       "337   0.159761  0.046461  0.967077  0.895423   0.123029            710   \n",
       "228   0.159278  0.045021  0.969227  0.895421   0.123031            700   \n",
       "1464  0.159693  0.044960  0.969387  0.895419   0.123032            740   \n",
       "403   0.159375  0.045632  0.968444  0.895410   0.123037            710   \n",
       "...        ...       ...       ...       ...        ...            ...   \n",
       "77    0.165126  0.062268  0.944962  0.887039   0.127866            700   \n",
       "1301  0.165644  0.062315  0.944806  0.887010   0.127883            740   \n",
       "1247  0.166118  0.060667  0.948025  0.886997   0.127890            730   \n",
       "1835  0.166294  0.061018  0.948138  0.886979   0.127900            750   \n",
       "2735  0.166764  0.061154  0.947697  0.886975   0.127902            780   \n",
       "245   0.166072  0.060873  0.948096  0.886969   0.127906            700   \n",
       "1919  0.165907  0.062495  0.944632  0.886958   0.127912            760   \n",
       "2351  0.165864  0.061490  0.946819  0.886957   0.127912            770   \n",
       "2375  0.165593  0.061286  0.946898  0.886934   0.127925            770   \n",
       "191   0.165875  0.061305  0.947137  0.886905   0.127942            700   \n",
       "281   0.166164  0.061023  0.947874  0.886904   0.127943            700   \n",
       "2483  0.166337  0.060977  0.948051  0.886902   0.127944            770   \n",
       "1319  0.165285  0.062135  0.945217  0.886888   0.127952            740   \n",
       "1763  0.164885  0.061243  0.947071  0.886887   0.127952            750   \n",
       "677   0.165834  0.062274  0.944786  0.886877   0.127958            720   \n",
       "1631  0.166020  0.062412  0.944864  0.886864   0.127965            750   \n",
       "2453  0.166156  0.060825  0.947621  0.886848   0.127974            770   \n",
       "2297  0.165657  0.061787  0.946065  0.886841   0.127978            770   \n",
       "2843  0.165126  0.062457  0.944634  0.886826   0.127987            790   \n",
       "3089  0.166748  0.060859  0.947885  0.886777   0.128014            790   \n",
       "1913  0.165558  0.062425  0.944848  0.886757   0.128026            760   \n",
       "2873  0.166189  0.062512  0.944390  0.886750   0.128029            790   \n",
       "2525  0.165835  0.062289  0.944962  0.886737   0.128037            780   \n",
       "581   0.165960  0.060727  0.948173  0.886688   0.128065            710   \n",
       "2111  0.165831  0.060915  0.947850  0.886605   0.128112            760   \n",
       "23    0.165722  0.062437  0.944509  0.886581   0.128125            700   \n",
       "2507  0.165031  0.062345  0.944594  0.886541   0.128148            780   \n",
       "365   0.166350  0.062273  0.944955  0.886530   0.128154            710   \n",
       "1229  0.166476  0.061003  0.947385  0.886527   0.128156            730   \n",
       "2711  0.166128  0.061385  0.946853  0.886436   0.128207            780   \n",
       "\n",
       "      max_featuresL  max_depthL  min_samples_splitL  min_samples_leafL  \\\n",
       "516              35          82                   2                  3   \n",
       "109              30          70                   5                  3   \n",
       "3109             40          94                   5                  3   \n",
       "2983             35          62                   5                  3   \n",
       "1836             40          78                   2                  3   \n",
       "1752             35          74                   2                  3   \n",
       "1771             35          86                   5                  3   \n",
       "145              30          94                   5                  3   \n",
       "1254             25          54                   2                  3   \n",
       "2772             40          78                   2                  3   \n",
       "2311             30          82                   5                  3   \n",
       "2694             35          78                   2                  3   \n",
       "2652             35          50                   2                  3   \n",
       "372              25          90                   2                  3   \n",
       "2725             35          98                   5                  3   \n",
       "205              35          82                   5                  3   \n",
       "1338             30          58                   2                  3   \n",
       "2605             30          70                   5                  3   \n",
       "1164             35          98                   2                  3   \n",
       "1699             30          90                   5                  3   \n",
       "540              35          98                   2                  3   \n",
       "2953             30          94                   5                  3   \n",
       "1135             35          78                   5                  3   \n",
       "2503             25          54                   5                  3   \n",
       "1153             35          90                   5                  3   \n",
       "2100             35          98                   2                  3   \n",
       "337              25          66                   5                  3   \n",
       "228              35          98                   2                  3   \n",
       "1464             35          90                   2                  3   \n",
       "403              30          58                   5                  3   \n",
       "...             ...         ...                 ...                ...   \n",
       "77               25          98                  17                  3   \n",
       "1301             25          82                  17                  3   \n",
       "1247             40          98                  17                  3   \n",
       "1835             40          74                  17                  3   \n",
       "2735             40          50                  17                  3   \n",
       "245              40          54                  17                  3   \n",
       "1919             25          78                  17                  3   \n",
       "2351             35          54                  17                  3   \n",
       "2375             35          70                  17                  3   \n",
       "191              35          70                  17                  3   \n",
       "281              40          78                  17                  3   \n",
       "2483             40          90                  17                  3   \n",
       "1319             25          94                  17                  3   \n",
       "1763             35          78                  17                  3   \n",
       "677              25          82                  17                  3   \n",
       "1631             25          94                  17                  3   \n",
       "2453             40          70                  17                  3   \n",
       "2297             30          70                  17                  3   \n",
       "2843             25          70                  17                  3   \n",
       "3089             40          78                  17                  3   \n",
       "1913             25          74                  17                  3   \n",
       "2873             25          90                  17                  3   \n",
       "2525             25          66                  17                  3   \n",
       "581              40          70                  17                  3   \n",
       "2111             40          50                  17                  3   \n",
       "23               25          62                  17                  3   \n",
       "2507             25          54                  17                  3   \n",
       "365              25          82                  17                  3   \n",
       "1229             40          86                  17                  3   \n",
       "2711             35          86                  17                  3   \n",
       "\n",
       "                                     featureImportanceL  \n",
       "516                Feature  Feature Importance\n",
       "55   ...  \n",
       "109                Feature  Feature Importance\n",
       "55   ...  \n",
       "3109               Feature  Feature Importance\n",
       "55   ...  \n",
       "2983               Feature  Feature Importance\n",
       "55   ...  \n",
       "1836               Feature  Feature Importance\n",
       "55   ...  \n",
       "1752               Feature  Feature Importance\n",
       "55   ...  \n",
       "1771               Feature  Feature Importance\n",
       "55   ...  \n",
       "145                Feature  Feature Importance\n",
       "55   ...  \n",
       "1254               Feature  Feature Importance\n",
       "55   ...  \n",
       "2772               Feature  Feature Importance\n",
       "55   ...  \n",
       "2311               Feature  Feature Importance\n",
       "55   ...  \n",
       "2694               Feature  Feature Importance\n",
       "55   ...  \n",
       "2652               Feature  Feature Importance\n",
       "55   ...  \n",
       "372                Feature  Feature Importance\n",
       "55   ...  \n",
       "2725               Feature  Feature Importance\n",
       "55   ...  \n",
       "205                Feature  Feature Importance\n",
       "55   ...  \n",
       "1338               Feature  Feature Importance\n",
       "55   ...  \n",
       "2605               Feature  Feature Importance\n",
       "55   ...  \n",
       "1164               Feature  Feature Importance\n",
       "55   ...  \n",
       "1699               Feature  Feature Importance\n",
       "55   ...  \n",
       "540                Feature  Feature Importance\n",
       "55   ...  \n",
       "2953               Feature  Feature Importance\n",
       "55   ...  \n",
       "1135               Feature  Feature Importance\n",
       "55   ...  \n",
       "2503               Feature  Feature Importance\n",
       "55   ...  \n",
       "1153               Feature  Feature Importance\n",
       "55   ...  \n",
       "2100               Feature  Feature Importance\n",
       "55   ...  \n",
       "337                Feature  Feature Importance\n",
       "55   ...  \n",
       "228                Feature  Feature Importance\n",
       "55   ...  \n",
       "1464               Feature  Feature Importance\n",
       "55   ...  \n",
       "403                Feature  Feature Importance\n",
       "55   ...  \n",
       "...                                                 ...  \n",
       "77                 Feature  Feature Importance\n",
       "55   ...  \n",
       "1301               Feature  Feature Importance\n",
       "55   ...  \n",
       "1247               Feature  Feature Importance\n",
       "55   ...  \n",
       "1835               Feature  Feature Importance\n",
       "55   ...  \n",
       "2735               Feature  Feature Importance\n",
       "55   ...  \n",
       "245                Feature  Feature Importance\n",
       "55   ...  \n",
       "1919               Feature  Feature Importance\n",
       "55   ...  \n",
       "2351               Feature  Feature Importance\n",
       "55   ...  \n",
       "2375               Feature  Feature Importance\n",
       "55   ...  \n",
       "191                Feature  Feature Importance\n",
       "55   ...  \n",
       "281                Feature  Feature Importance\n",
       "55   ...  \n",
       "2483               Feature  Feature Importance\n",
       "55   ...  \n",
       "1319               Feature  Feature Importance\n",
       "55   ...  \n",
       "1763               Feature  Feature Importance\n",
       "55   ...  \n",
       "677                Feature  Feature Importance\n",
       "55   ...  \n",
       "1631               Feature  Feature Importance\n",
       "55   ...  \n",
       "2453               Feature  Feature Importance\n",
       "55   ...  \n",
       "2297               Feature  Feature Importance\n",
       "55   ...  \n",
       "2843               Feature  Feature Importance\n",
       "55   ...  \n",
       "3089               Feature  Feature Importance\n",
       "55   ...  \n",
       "1913               Feature  Feature Importance\n",
       "55   ...  \n",
       "2873               Feature  Feature Importance\n",
       "55   ...  \n",
       "2525               Feature  Feature Importance\n",
       "55   ...  \n",
       "581                Feature  Feature Importance\n",
       "55   ...  \n",
       "2111               Feature  Feature Importance\n",
       "55   ...  \n",
       "23                 Feature  Feature Importance\n",
       "55   ...  \n",
       "2507               Feature  Feature Importance\n",
       "55   ...  \n",
       "365                Feature  Feature Importance\n",
       "55   ...  \n",
       "1229               Feature  Feature Importance\n",
       "55   ...  \n",
       "2711               Feature  Feature Importance\n",
       "55   ...  \n",
       "\n",
       "[3120 rows x 11 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the best test_rmse\n",
    "result.sort_values(by='rmse_oobL', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Feature Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>0.324953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>0.162354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ExterQual</td>\n",
       "      <td>0.081055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>YearsOld</td>\n",
       "      <td>0.056172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>TotalBsmtSF</td>\n",
       "      <td>0.044571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>GarageCars</td>\n",
       "      <td>0.041914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>KitchenQual</td>\n",
       "      <td>0.036563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1stFlrSF</td>\n",
       "      <td>0.027497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>LotArea</td>\n",
       "      <td>0.019888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GarageType</td>\n",
       "      <td>0.018782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BsmtFinSF1</td>\n",
       "      <td>0.016569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BsmtQual</td>\n",
       "      <td>0.015964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Bath</td>\n",
       "      <td>0.014751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GarageYrBlt</td>\n",
       "      <td>0.013871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2ndFlrSF</td>\n",
       "      <td>0.011275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Fireplaces</td>\n",
       "      <td>0.010550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>YearSinceRemodel</td>\n",
       "      <td>0.009998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>OverallCond</td>\n",
       "      <td>0.009961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LotFrontage</td>\n",
       "      <td>0.009273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>GarageQual</td>\n",
       "      <td>0.004787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Neighborhood</td>\n",
       "      <td>0.004575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BsmtFinType1</td>\n",
       "      <td>0.004537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BsmtUnfSF</td>\n",
       "      <td>0.004279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>OpenPorchSF</td>\n",
       "      <td>0.003605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>MasVnrArea</td>\n",
       "      <td>0.003401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GarageCond</td>\n",
       "      <td>0.003398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>WoodDeckSF</td>\n",
       "      <td>0.002978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CentralAir</td>\n",
       "      <td>0.002772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>GarageFinish</td>\n",
       "      <td>0.002501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>MSZoning</td>\n",
       "      <td>0.002373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>BsmtBath</td>\n",
       "      <td>0.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BsmtCond</td>\n",
       "      <td>0.001587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Exterior2nd</td>\n",
       "      <td>0.001498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Exterior1st</td>\n",
       "      <td>0.001425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>HouseStyle</td>\n",
       "      <td>0.001240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>HeatingQC</td>\n",
       "      <td>0.001212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BldgType</td>\n",
       "      <td>0.001035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>LotShape</td>\n",
       "      <td>0.000995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>KitchenAbvGr</td>\n",
       "      <td>0.000964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Foundation</td>\n",
       "      <td>0.000883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>LandContour</td>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>PavedDrive</td>\n",
       "      <td>0.000712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>LotConfig</td>\n",
       "      <td>0.000618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EnclosedPorch</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SaleType</td>\n",
       "      <td>0.000569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>RoofStyle</td>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LandSlope</td>\n",
       "      <td>0.000494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>MasVnrType</td>\n",
       "      <td>0.000462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Fence</td>\n",
       "      <td>0.000411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Condition1</td>\n",
       "      <td>0.000406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alley</td>\n",
       "      <td>0.000382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ScreenPorch</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Electrical</td>\n",
       "      <td>0.000291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BsmtFinSF2</td>\n",
       "      <td>0.000218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BsmtFinType2</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>LowQualFinSF</td>\n",
       "      <td>0.000186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>MiscVal</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Heating</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>RoofMatl</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3SsnPorch</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Feature Importance\n",
       "55       OverallQual            0.324953\n",
       "33         GrLivArea            0.162354\n",
       "20         ExterQual            0.081055\n",
       "68          YearsOld            0.056172\n",
       "64       TotalBsmtSF            0.044571\n",
       "27        GarageCars            0.041914\n",
       "38       KitchenQual            0.036563\n",
       "0           1stFlrSF            0.027497\n",
       "41           LotArea            0.019888\n",
       "31        GarageType            0.018782\n",
       "8         BsmtFinSF1            0.016569\n",
       "12          BsmtQual            0.015964\n",
       "67              Bath            0.014751\n",
       "32       GarageYrBlt            0.013871\n",
       "1           2ndFlrSF            0.011275\n",
       "24        Fireplaces            0.010550\n",
       "69  YearSinceRemodel            0.009998\n",
       "54       OverallCond            0.009961\n",
       "43       LotFrontage            0.009273\n",
       "30        GarageQual            0.004787\n",
       "52      Neighborhood            0.004575\n",
       "10      BsmtFinType1            0.004537\n",
       "13         BsmtUnfSF            0.004279\n",
       "53       OpenPorchSF            0.003605\n",
       "48        MasVnrArea            0.003401\n",
       "28        GarageCond            0.003398\n",
       "65        WoodDeckSF            0.002978\n",
       "14        CentralAir            0.002772\n",
       "29      GarageFinish            0.002501\n",
       "47          MSZoning            0.002373\n",
       "..               ...                 ...\n",
       "66          BsmtBath            0.001679\n",
       "6           BsmtCond            0.001587\n",
       "22       Exterior2nd            0.001498\n",
       "21       Exterior1st            0.001425\n",
       "36        HouseStyle            0.001240\n",
       "35         HeatingQC            0.001212\n",
       "5           BldgType            0.001035\n",
       "44          LotShape            0.000995\n",
       "37      KitchenAbvGr            0.000964\n",
       "25        Foundation            0.000883\n",
       "39       LandContour            0.000722\n",
       "56        PavedDrive            0.000712\n",
       "42         LotConfig            0.000618\n",
       "18     EnclosedPorch            0.000600\n",
       "61          SaleType            0.000569\n",
       "59         RoofStyle            0.000520\n",
       "40         LandSlope            0.000494\n",
       "49        MasVnrType            0.000462\n",
       "23             Fence            0.000411\n",
       "15        Condition1            0.000406\n",
       "3              Alley            0.000382\n",
       "62       ScreenPorch            0.000312\n",
       "17        Electrical            0.000291\n",
       "9         BsmtFinSF2            0.000218\n",
       "11      BsmtFinType2            0.000197\n",
       "45      LowQualFinSF            0.000186\n",
       "50           MiscVal            0.000048\n",
       "34           Heating            0.000022\n",
       "58          RoofMatl            0.000017\n",
       "2          3SsnPorch            0.000002\n",
       "\n",
       "[67 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.iloc[516]['featureImportanceL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #graph max depth vs Score\n",
    "# train_vs_test=result.loc[:,['max_featuresL',\"rmse_oobL\",'train_rmse_L']]\n",
    "# plt.plot('max_featuresL', 'train_rmse_L', 'r--', data=train_vs_test, label = 'rmse')\n",
    "# plt.plot('max_featuresL', 'rmse_oobL', 'b--', data=train_vs_test, label = 'rmse_oob')\n",
    "# plt.legend(loc='best', mode=\"expand\")\n",
    "# plt.xlabel('max_featuresL')\n",
    "# plt.ylabel('Score')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
