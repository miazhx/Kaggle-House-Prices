{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matplotlib\n",
    "import seaborn as sns\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(df_raw,remove_outlier = False,remove_hard_to_fit = False,linear_model = False, get_dummies=False, label_encode=False ):\n",
    "\n",
    "\t# Make a copy so the original dataframe will not be altered.\n",
    "    df_processed = df_raw.copy()\n",
    "    \n",
    "    \n",
    "\t# Remove outliers.\n",
    "    outlier_list = [524, 1299, 463, 31, 534, 1433, 739, 1159, 108, 1231, 971, 1424]\n",
    "    df_processed = df_processed.drop(outlier_list)\n",
    "\n",
    "    \n",
    "    ## Missing values\n",
    "    \n",
    "    # 259 LotFrontage  - replace missing value with 0 \n",
    "    df_processed.LotFrontage = df_processed.LotFrontage.fillna(0)\n",
    "\n",
    "    # 1369 Alley - replace with None\n",
    "    df_processed.Alley = df_processed.Alley.fillna('None')\n",
    "\n",
    "    # 8 MasVnrType and MasVnrArea - replace MasVnrType with None and MasVnrArea with 0\n",
    "    df_processed.MasVnrType = df_processed.MasVnrType.fillna('None')\n",
    "    df_processed.MasVnrArea = df_processed.MasVnrArea.fillna(0)\n",
    "\n",
    "    # 37 basement: BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2- replace with Nb\n",
    "    df_processed.BsmtQual = df_processed.BsmtQual.fillna('Nb')\n",
    "    df_processed.BsmtCond = df_processed.BsmtCond.fillna('Nb')\n",
    "    df_processed.BsmtExposure = df_processed.BsmtExposure.fillna('Nb')\n",
    "    df_processed.BsmtFinType1 = df_processed.BsmtFinType1.fillna('Nb')\n",
    "    df_processed.BsmtFinType2 = df_processed.BsmtFinType2.fillna('Nb')\n",
    "    df_processed.TotalBsmtSF = df_processed.TotalBsmtSF.fillna(0)\n",
    "    \n",
    "\n",
    "    # 690 FireplaceQu - replace with Nf\n",
    "    df_processed.FireplaceQu = df_processed.FireplaceQu.fillna('Nf')\n",
    "\n",
    "    # 81 Garage: GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond - replace with Ng and year with 0 \n",
    "    df_processed.GarageType = df_processed.GarageType.fillna('Ng')\n",
    "    df_processed.GarageFinish = df_processed.GarageFinish.fillna('Ng')\n",
    "    df_processed.GarageQual = df_processed.GarageQual.fillna('Ng')\n",
    "    df_processed.GarageCond = df_processed.GarageCond.fillna('Ng')\n",
    "    df_processed.GarageYrBlt = df_processed.GarageYrBlt.fillna(0)\n",
    "\n",
    "    # 1453 PoolQC - replace with Np\n",
    "    df_processed.PoolQC = df_processed.PoolQC.fillna('Np')\n",
    "\n",
    "    # 1179 Fence - replace with Nf\n",
    "    df_processed.Fence = df_processed.Fence.fillna('Nf')\n",
    "\n",
    "    # 1406 MiscFeature - replace with None    \n",
    "    df_processed.MiscFeature = df_processed.MiscFeature.fillna('None')\n",
    "\n",
    "    # 1 Electrical\n",
    "    df_processed = df_processed[pd.notnull(df_processed.Electrical)]\n",
    "\n",
    "    ## Combine columns and drop multicollinear columns \n",
    "    \n",
    "    # combine bathroom quanlitity \n",
    "    df_processed['BsmtBath'] = df_processed.BsmtFullBath + df_processed.BsmtHalfBath * 0.5\n",
    "    df_processed['Bath'] = df_processed.FullBath + df_processed.HalfBath * 0.5\n",
    "    df_processed = df_processed.drop(['BsmtFullBath', 'BsmtHalfBath','FullBath','HalfBath'], axis=1)\n",
    "\n",
    "    # drop TotalBsmtSF - multicollinearaty\n",
    "    #df_processed = df_processed.drop(['TotalBsmtSF'], axis=1)\n",
    "\n",
    "    # drop GrLivArea - multicollinearaty\n",
    "    #df_processed = df_processed.drop(['GrLivArea'], axis=1)\n",
    "\n",
    "    # drop GarageArea - higher correlation than GarageACars, results are better as well\n",
    "    df_processed = df_processed.drop(['GarageArea'], axis=1) \n",
    "    \n",
    "    \n",
    "\t# Feature Transformation - take the logarithm of the features.\n",
    "    #Linear_Num_Cols = ['TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'LotArea', 'GarageArea', 'TotRmsAbvGrd', 'TotalSF', 'BsmtFinSF1']\n",
    "    df_processed.SalePrice = np.log(df_processed.SalePrice)\n",
    "    df_processed.GrLivArea = np.log(df_processed.GrLivArea)\n",
    "    df_processed.TotalBsmtSF = np.log(df_processed.TotalBsmtSF+1)\n",
    "#     df_processed.LotArea = np.log(df_processed.LotArea) -- performance decreases\n",
    "#     df_processed.GarageArea = np.log(df_processed.GarageArea)\n",
    "\n",
    "\n",
    "\n",
    "\t# Categorical Features Processsing\n",
    "\n",
    "\t# MSSubClass processing - MSSubClass 20-90 contains only duplicate information with HouseStyle and YearBuilt.\n",
    "    df_processed['MSSubClass'] = df_processed['MSSubClass'].replace(['20','30','40','45','50','60','70','75','80','85'], '0')\n",
    "\n",
    "    # Convert numerical to categorical. \n",
    "    df_processed[['MSSubClass','OverallQual','OverallCond']] = df_processed[['MSSubClass','OverallQual','OverallCond']].astype(str)\n",
    "\n",
    "    #Get Dummies \n",
    "    \n",
    "    if get_dummies:\n",
    "        df_processed = pd.get_dummies(df_processed, columns=df_processed.select_dtypes(include=['object']).columns, drop_first=True)\n",
    "    \n",
    "    \n",
    "    #get label encoder. categorical data change to numerical values\n",
    "    if label_encode:\n",
    "        le = LabelEncoder()\n",
    "        categorical_ordinal_col=df_processed.select_dtypes(include=['object']).columns.to_list()\n",
    "        df_processed[categorical_ordinal_col]=df_processed[categorical_ordinal_col].apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "   #---Multiply features: \n",
    "#     df_processed[\"add_OverallGrade\"] = df_processed[\"OverallQual\"] * df_processed[\"OverallCond\"]\n",
    "#     df_processed[\"add_GarageGrade\"] = df_processed[\"GarageQual\"] * df_processed[\"GarageCond\"]\n",
    "#     df_processed[\"add_ExterGrade\"] = df_processed[\"ExterQual\"] * df_processed[\"ExterCond\"]\n",
    "#     df_processed[\"add_KitchenScore\"] = df_processed[\"KitchenAbvGr\"] * df_processed[\"KitchenQual\"]\n",
    "#     df_processed[\"add_FireplaceScore\"] = df_processed[\"Fireplaces\"] * df_processed[\"FireplaceQu\"]\n",
    "#     df_processed[\"add_GarageScore\"] = df_processed[\"GarageArea\"] * df_processed[\"GarageQual\"]\n",
    "#     df_processed[\"add_PoolScore\"] = df_processed[\"PoolArea\"] * df_processed[\"PoolQC\"]\n",
    "#     df_processed['add_GrLivArea*OvQual'] = df_processed['GrLivArea'] * df_processed['OverallQual']\n",
    "#     df_processed['add_QualOverall*Exter*Kitch*Bsmt*Garage'] = df_processed['OverallQual'] * df_processed['ExterQual'] * df_processed['KitchenQual'] * df_processed['BsmtQual'] * df_processed['GarageQual']\n",
    "\n",
    "\n",
    "\n",
    "    return df_processed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_ordinal_col=['Alley',\n",
    "#  'BldgType',\n",
    "#  'BsmtCond',\n",
    "#  'BsmtExposure',\n",
    "#  'BsmtFinType1',\n",
    "#  'BsmtFinType2',\n",
    "#  'BsmtQual',\n",
    "#  'CentralAir',\n",
    "#  'Condition1',\n",
    "#  'Condition2',\n",
    "#  'Electrical',\n",
    "#  'ExterCond',\n",
    "#  'ExterQual',\n",
    "#  'Exterior1st',\n",
    "#  'Exterior2nd',\n",
    "#  'Fence',\n",
    "#  'FireplaceQu',\n",
    "#  'Foundation',\n",
    "#  'Functional',\n",
    "#  'GarageCond',\n",
    "#  'GarageFinish',\n",
    "#  'GarageQual',\n",
    "#  'GarageType',\n",
    "#  'Heating',\n",
    "#  'HeatingQC',\n",
    "#  'HouseStyle',\n",
    "#  'KitchenQual',\n",
    "#  'LandContour',\n",
    "#  'LandSlope',\n",
    "#  'LotConfig',\n",
    "#  'LotShape',\n",
    "#  'MSSubClass',\n",
    "#  'MSZoning',\n",
    "#  'MasVnrType',\n",
    "#  'MiscFeature',\n",
    "#  'Neighborhood',\n",
    "#  'OverallCond',\n",
    "#  'OverallQual',\n",
    "#  'PavedDrive',\n",
    "#  'PoolQC',\n",
    "#  'RoofMatl',\n",
    "#  'RoofStyle',\n",
    "#  'SaleCondition',\n",
    "#  'SaleType',\n",
    "#  'Street',\n",
    "#  'Utilities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #List of numerical columns\n",
    "# numerical_col=['LotFrontage',\n",
    "#  'LotArea',\n",
    "#  'YearBuilt',\n",
    "#  'YearRemodAdd',\n",
    "#  'MasVnrArea',\n",
    "#  'BsmtFinSF1',\n",
    "#  'BsmtFinSF2',\n",
    "#  'BsmtUnfSF',\n",
    "#  '1stFlrSF',\n",
    "#  '2ndFlrSF',\n",
    "#  'LowQualFinSF',\n",
    "#  'BedroomAbvGr',\n",
    "#  'KitchenAbvGr',\n",
    "#  'TotRmsAbvGrd',\n",
    "#  'Fireplaces',\n",
    "#  'GarageYrBlt',\n",
    "#  'GarageCars',\n",
    "#  'WoodDeckSF',\n",
    "#  'OpenPorchSF',\n",
    "#  'EnclosedPorch',\n",
    "#  '3SsnPorch',\n",
    "#  'ScreenPorch',\n",
    "#  'PoolArea',\n",
    "#  'MiscVal',\n",
    "#  'MoSold',\n",
    "#  'YrSold',\n",
    "#  'SalePrice',\n",
    "#  'BsmtBath',\n",
    "#  'Bath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>BsmtBath</th>\n",
       "      <th>Bath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12.247694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12.109011</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12.317167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>11.849398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12.429216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  MSZoning  LotFrontage  LotArea  Street  Alley  LotShape  \\\n",
       "0   1           9         3         65.0     8450       1      1         3   \n",
       "1   2           4         3         80.0     9600       1      1         3   \n",
       "2   3           9         3         68.0    11250       1      1         0   \n",
       "3   4          10         3         60.0     9550       1      1         0   \n",
       "4   5           9         3         84.0    14260       1      1         0   \n",
       "\n",
       "   LandContour  Utilities  ...  Fence  MiscFeature  MiscVal  MoSold  YrSold  \\\n",
       "0            3          0  ...      4            1        0       2    2008   \n",
       "1            3          0  ...      4            1        0       5    2007   \n",
       "2            3          0  ...      4            1        0       9    2008   \n",
       "3            3          0  ...      4            1        0       2    2006   \n",
       "4            3          0  ...      4            1        0      12    2008   \n",
       "\n",
       "   SaleType  SaleCondition  SalePrice  BsmtBath  Bath  \n",
       "0         8              4  12.247694       1.0   2.5  \n",
       "1         8              4  12.109011       0.5   2.0  \n",
       "2         8              4  12.317167       1.0   2.5  \n",
       "3         8              0  11.849398       1.0   1.0  \n",
       "4         8              4  12.429216       1.0   2.5  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data prep\n",
    "data_processed_label_encode=data_process(df_raw,label_encode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Add MLFLOW\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import math\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "#Randomized search CV with Random Forrest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train, test = train_test_split(data_processed_label_encode)\n",
    "\n",
    "# The predicted column is \"SalePrice\" .\n",
    "train_x = train.drop([\"SalePrice\"], axis=1)\n",
    "test_x = test.drop([\"SalePrice\"], axis=1)\n",
    "train_y = train[[\"SalePrice\"]]\n",
    "test_y = test[[\"SalePrice\"]]\n",
    "\n",
    "def random_search_rf(n_estimators,\n",
    "                     max_features, max_depth,\n",
    "                     min_samples_split,min_samples_leaf):\n",
    "    \n",
    "    \n",
    "    rf = RandomForestRegressor(oob_score=True)\n",
    "\n",
    "\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                  }\n",
    "    print(random_grid)\n",
    "\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf = RandomForestRegressor()\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "    rf_random.fit(train_x, train_y.values.ravel())\n",
    "\n",
    "    print('random forrest best_params per random search')\n",
    "    print (rf_random.best_params_)\n",
    "\n",
    "\n",
    "    best_n_estimator=rf_random.best_params_.get('n_estimators')\n",
    "    best_max_features=rf_random.best_params_.get(\"max_features\")\n",
    "    best_max_depth=rf_random.best_params_.get('max_depth')\n",
    "    best_min_samples_split=rf_random.best_params_.get('min_samples_split')\n",
    "    best_min_samples_leaf=rf_random.best_params_.get(\"best_min_samples_leaf\")\n",
    "    \n",
    "    #Train random forest based on the best parameters found\n",
    "    rf = RandomForestRegressor( n_estimators=best_n_estimator,\n",
    "                max_features=best_max_features,\n",
    "                max_depth=best_max_depth,\n",
    "                min_samples_split=best_min_samples_split,\n",
    "                min_samples_leaf=best_min_samples_split,\n",
    "                oob_score =True)\n",
    "\n",
    "    # Train the model on train.csv data\n",
    "    rf.fit(train_x, train_y.values.ravel())\n",
    "    y_pred_train = rf.predict(train_x)\n",
    "\n",
    "    #calculate rsme for train data\n",
    "    rmse = math.sqrt(sum((train_y['SalePrice'].to_numpy()-y_pred_train)**2)/len(train_x))\n",
    "    print('best model parameter Rmse: ',rmse)\n",
    "\n",
    "    mae = mean_absolute_error(train_y['SalePrice'].to_numpy(), y_pred_train)\n",
    "    print ('best model parameter mae:', mae)\n",
    "\n",
    "    r2 = r2_score(train_y['SalePrice'].to_numpy(), y_pred_train)\n",
    "    print ('best model r2 score:', r2)\n",
    "\n",
    "    oob = rf.oob_score_\n",
    "    print('best model parameter Oob score: ',oob)\n",
    "    oob_pred = rf.oob_prediction_\n",
    "    rmse_oob = math.sqrt(sum((train_y['SalePrice'].to_numpy()-oob_pred)**2)/len(train_x))\n",
    "    print('Rmse using oob prediction: ', rmse_oob)\n",
    "\n",
    "    # #read and process test.csv\n",
    "    # df_test=pd.read_csv('test.csv')\n",
    "    # df_test_processed=data_process(df_test, label_encode=False) #It should be TRUE********\n",
    "    # df_test_processed.drop('Id', axis=1, inplace=True)\n",
    "\n",
    "    return (rmse, mae, r2, oob, rmse_oob,best_n_estimator,best_max_features, best_max_depth,best_min_samples_split,best_min_samples_leaf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run random_search_rf function with start parameters \n",
    "\n",
    "\n",
    "\n",
    "# Number of trees in random forest\n",
    "#n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "n_estimators=[100]\n",
    "# Number of features to consider at every split\n",
    "max_features = [45]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 10, 15]\n",
    "\n",
    "\n",
    "random_search_rf(n_estimators,max_features, max_depth,min_samples_split,min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Add MLFLOW, grid search with random forrest\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import math\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "#Grid Search with Random Forrest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train, test = train_test_split(data_processed_label_encode)\n",
    "\n",
    "# The predicted column is \"SalePrice\" .\n",
    "train_x = train.drop([\"SalePrice\"], axis=1)\n",
    "test_x = test.drop([\"SalePrice\"], axis=1)\n",
    "train_y = train[[\"SalePrice\"]]\n",
    "test_y = test[[\"SalePrice\"]]\n",
    "\n",
    "\n",
    "def grid_search_rf(n_estimators,max_features, max_depth,min_samples_split,min_samples_leaf):\n",
    "\n",
    "    rf = RandomForestRegressor(oob_score=True)\n",
    "\n",
    "    \n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                  }\n",
    "    \n",
    "    print(random_grid)\n",
    "\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf = RandomForestRegressor()\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = GridSearchCV(estimator = rf, param_grid = random_grid, verbose=2, n_jobs = -1)# Fit the random search model\n",
    "    rf_random.fit(train_x, train_y.values.ravel())\n",
    "\n",
    "    print('random forrest best_params per random search')\n",
    "    print (rf_random.best_params_)\n",
    "\n",
    "    best_n_estimator=rf_random.best_params_.get('n_estimators')\n",
    "    best_max_features=rf_random.best_params_.get(\"max_features\")\n",
    "    best_max_depth=rf_random.best_params_.get('max_depth')\n",
    "    best_min_samples_split=rf_random.best_params_.get('min_samples_split')\n",
    "    best_min_samples_leaf=rf_random.best_params_.get(\"min_samples_leaf\")\n",
    "    \n",
    "    #Train random forest based on the best parameters found\n",
    "    rf = RandomForestRegressor( n_estimators=best_n_estimator,\n",
    "                max_features=best_max_features,\n",
    "               max_depth=best_max_depth,\n",
    "               min_samples_split=best_min_samples_split,\n",
    "               min_samples_leaf=best_min_samples_leaf,\n",
    "               oob_score =True)\n",
    "\n",
    "    # Train the model on train.csv data\n",
    "    rf.fit(train_x, train_y.values.ravel())\n",
    "    y_pred_train = rf.predict(train_x)\n",
    "\n",
    "    #calculate rsme for train data\n",
    "    rmse = math.sqrt(sum((train_y['SalePrice'].to_numpy()-y_pred_train)**2)/len(train_x))\n",
    "    print('best model parameter Rmse: ',rmse)\n",
    "\n",
    "    mae = mean_absolute_error(train_y['SalePrice'].to_numpy(), y_pred_train)\n",
    "    print ('best model parameter mae:', mae)\n",
    "\n",
    "    r2 = r2_score(train_y['SalePrice'].to_numpy(), y_pred_train)\n",
    "    print ('best model r2 score:', r2)\n",
    "\n",
    "    oob = rf.oob_score_\n",
    "    print('best model parameter Oob score: ',oob)\n",
    "    oob_pred = rf.oob_prediction_\n",
    "    rmse_oob = math.sqrt(sum((train_y['SalePrice'].to_numpy()-oob_pred)**2)/len(train_x))\n",
    "    print('Rmse using oob prediction: ', rmse_oob)\n",
    "\n",
    "    # #read and process test.csv\n",
    "    # df_test=pd.read_csv('test.csv')\n",
    "    # df_test_processed=data_process(df_test, label_encode=False) #It should be TRUE********\n",
    "    # df_test_processed.drop('Id', axis=1, inplace=True)\n",
    "\n",
    "    return (rmse, mae, r2, oob, rmse_oob,best_n_estimator,best_max_features, best_max_depth,best_min_samples_split,best_min_samples_leaf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Run grid search for random forest\n",
    "\n",
    "# # Number of trees in random forest\n",
    "#n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "n_estimators=[100]\n",
    "# Number of features to consider at every split\n",
    "max_features = [45]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [90]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf  = [3]\n",
    "\n",
    "grid_search_rf(n_estimators,max_features, max_depth,min_samples_split,min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
