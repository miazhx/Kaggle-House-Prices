{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matplotlib\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "def data_process(test=False):\n",
    "    \n",
    "    \n",
    "    # Read file for train or test.\n",
    "    \n",
    "    df_raw_train = pd.read_csv('train.csv',index_col=0)\n",
    "    df_raw_test = pd.read_csv('test.csv',index_col=0)\n",
    "    \n",
    "#     print(df_raw_train.shape)\n",
    "#     print(df_raw_test.shape)\n",
    "        \n",
    "    # Remove outliers in training set.   \n",
    "    outlier_list_scatter = [524, 1299]\n",
    "    outlier_list_hard_to_fit = [463, 31, 534, 1433, 739, 1159, 108, 1231, 971, 1424 ]\n",
    "    outlier_list = outlier_list_scatter + outlier_list_hard_to_fit\n",
    "    df_raw_train = df_raw_train.drop(outlier_list)\n",
    "    \n",
    "    # Store the sale price information\n",
    "    sale_price_train = df_raw_train['SalePrice']\n",
    "    \n",
    "    # Drop the sales price column to only keep the features\n",
    "    df_raw_train = df_raw_train.drop(['SalePrice'], axis = 1)\n",
    "#     print(df_raw_train.shape)\n",
    "    \n",
    "    # Merge train and test df together for later process\n",
    "    df_processed = pd.concat([df_raw_train, df_raw_test], sort=True)\n",
    "    \n",
    "\n",
    "    # Combine bathroom quanlitity \n",
    "    df_processed['BsmtBath'] = df_processed.BsmtFullBath + df_processed.BsmtHalfBath * 0.5\n",
    "    df_processed['Bath'] = df_processed.FullBath + df_processed.HalfBath * 0.5\n",
    "       \n",
    "    \n",
    "    ## Drop multicollinear columns \n",
    "    df_processed = df_processed.drop(['BsmtFullBath', 'BsmtHalfBath','FullBath','HalfBath'], axis=1)\n",
    "    \n",
    "    \n",
    "    ## Missing values\n",
    "    \n",
    "    # 259 LotFrontage  - replace missing value with 0 \n",
    "#     df_processed.LotFrontage = df_processed.LotFrontage.fillna(0)\n",
    "    df_processed[\"LotFrontage\"] = df_processed.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    # 1369 Alley - replace with None\n",
    "    df_processed.Alley = df_processed.Alley.fillna('None')\n",
    "\n",
    "    # 8 MasVnrType and MasVnrArea - replace MasVnrType with None and MasVnrArea with 0\n",
    "    df_processed.MasVnrType = df_processed.MasVnrType.fillna('None')\n",
    "    df_processed.MasVnrArea = df_processed.MasVnrArea.fillna(0)\n",
    "\n",
    "    # 37 basement: BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2- replace with None\n",
    "    df_processed.BsmtQual = df_processed.BsmtQual.fillna('None')\n",
    "    df_processed.BsmtCond = df_processed.BsmtCond.fillna('None')\n",
    "    df_processed.BsmtExposure = df_processed.BsmtExposure.fillna('None')\n",
    "    df_processed.BsmtFinType1 = df_processed.BsmtFinType1.fillna('None')\n",
    "    df_processed.BsmtFinType2 = df_processed.BsmtFinType2.fillna('None')\n",
    "    df_processed.TotalBsmtSF = df_processed.TotalBsmtSF.fillna(0)\n",
    "    \n",
    "\n",
    "    # 690 FireplaceQu - replace with None\n",
    "    df_processed.FireplaceQu = df_processed.FireplaceQu.fillna('None')\n",
    "\n",
    "    # 81 Garage: GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond - replace with None and year with 0 \n",
    "    df_processed.GarageType = df_processed.GarageType.fillna('None')\n",
    "    df_processed.GarageFinish = df_processed.GarageFinish.fillna('None')\n",
    "    df_processed.GarageQual = df_processed.GarageQual.fillna('None')\n",
    "    df_processed.GarageCond = df_processed.GarageCond.fillna('None')\n",
    "    df_processed.GarageYrBlt = df_processed.GarageYrBlt.fillna(0)\n",
    "\n",
    "    # 1453 PoolQC - replace with None\n",
    "    df_processed.PoolQC = df_processed.PoolQC.fillna('None')\n",
    "\n",
    "    # 1179 Fence - replace with None\n",
    "    df_processed.Fence = df_processed.Fence.fillna('None')\n",
    "\n",
    "    # 1406 MiscFeature - replace with None    \n",
    "    df_processed.MiscFeature = df_processed.MiscFeature.fillna('None')\n",
    "\n",
    "    # 1 Electrical\n",
    "    df_processed = df_processed[pd.notnull(df_processed.Electrical)]\n",
    "    \n",
    "    #Missing Value only in test data \n",
    "    \n",
    "    # MSZoning (The general zoning classification) : 'RL' is by far the most common value. So we can fill in missing values with 'RL'\n",
    "    df_processed['MSZoning'] = df_processed['MSZoning'].fillna(df_processed['MSZoning'].mode()[0])\n",
    "\n",
    "    # Utilities : For this categorical feature all records are \"AllPub\", except for one \"NoSeWa\" and 2 NA . Since the house with 'NoSewa' is in the training set, this feature won't help in predictive modelling. We can then safely remove it.\n",
    "    df_processed.drop(['Utilities'], axis=1,inplace=True)\n",
    "\n",
    "    # Exterior1st and Exterior2nd : Again Both Exterior 1 & 2 have only one missing value. We will just substitute in the most common string\n",
    "    df_processed['Exterior1st'] = df_processed['Exterior1st'].fillna(df_processed['Exterior1st'].mode()[0])\n",
    "    df_processed['Exterior2nd'] = df_processed['Exterior2nd'].fillna(df_processed['Exterior2nd'].mode()[0]) \n",
    "    \n",
    "    # BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtBath : missing values are likely zero for having no basement\n",
    "    for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtBath'):\n",
    "        df_processed[col] = df_processed[col].fillna(0)    \n",
    "    \n",
    "    #Garage Cars \n",
    "    df_processed.GarageCars = df_processed.GarageCars.fillna(0) \n",
    "    \n",
    "    # SaleType : Fill in again with most frequent which is \"WD\"\n",
    "    df_processed['SaleType'] = df_processed['SaleType'].fillna(df_processed['SaleType'].mode()[0])\n",
    "    \n",
    "    # KitchenQual: Only one NA value, and same as Electrical, we set 'TA' (which is the most frequent) for the missing value in KitchenQual.\n",
    "    df_processed['KitchenQual'] = df_processed['KitchenQual'].fillna(df_processed['KitchenQual'].mode()[0])    \n",
    "    \n",
    "    # Functional : data description says NA means typical\n",
    "    df_processed[\"Functional\"] = df_processed[\"Functional\"].fillna(\"Typ\")    \n",
    "    \n",
    "\n",
    "    # drop GarageArea - higher correlation than GarageACars, results are better as well\n",
    "    df_processed = df_processed.drop(['GarageArea'], axis=1) \n",
    "    df_processed = df_processed.drop(['MiscFeature'], axis=1) \n",
    "#     df_processed = df_processed.drop(['1stFlrSF'], axis=1) \n",
    "    df_processed = df_processed.drop(['TotRmsAbvGrd'], axis=1) \n",
    "\n",
    "    \n",
    "    # Feature Transformation - take the logarithm of the features.\n",
    "    #Linear_Num_Cols = ['TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'LotArea', 'GarageArea', 'TotRmsAbvGrd', 'TotalSF', 'BsmtFinSF1']\n",
    "    df_processed.GrLivArea = np.log(df_processed.GrLivArea)\n",
    "    df_processed.TotalBsmtSF = np.log(df_processed.TotalBsmtSF+1)\n",
    "#     df_processed.LotArea = np.log(df_processed.LotArea) -- performance decreases\n",
    "#     df_processed.GarageArea = np.log(df_processed.GarageArea) -- will drop column \n",
    "\n",
    "\n",
    "\n",
    "    # Categorical Features Processsing\n",
    "\n",
    "    # MSSubClass processing - MSSubClass 20-90 contains only duplicate information with HouseStyle and YearBuilt.\n",
    "    df_processed['MSSubClass'] = df_processed['MSSubClass'].replace(['20','30','40','45','50','60','70','75','80','85'], '0')\n",
    "\n",
    "    # Convert numerical to categorical. \n",
    "    df_processed['MSSubClass'] = df_processed['MSSubClass'].astype(str)\n",
    "\n",
    "    #Encode some categorical features as ordered numbers when there is information in the order.\n",
    "    df_processed = df_processed.replace({\"Alley\" : {\"None\":0,\"Grvl\" : 1, \"Pave\" : 2},\n",
    "#                        \"Neighborhood\" : {\"SWISU\" : 1, \"IDOTRR\" : 2, \"OldTown\" : 3, \"BrDale\" : 4, \"Blueste\": 5,\n",
    "#                        \"Edwards\" : 6, \"MeadowV\" : 7, \"BrkSide\" : 8, \"NWAmes\" : 9, \"NAmes\" : 10, \"NPkVill\" : 11, \"Sawyer\" : 12, \"Gilbert\": 13, \n",
    "#                        \"SawyerW\" : 14, \"Crawfor\" : 15, \"ClearCr\" : 16, \"Mitchel\" : 17, \"NoRidge\": 18, \"Blmngtn\" : 19, \"CollgCr\" : 20, \"Timber\" : 21, \"Somerst\" : 22, \"Veenker\": 23, \"NridgHt\" : 24, \"StoneBr\": 25 },\n",
    "                       \"BsmtCond\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"BsmtExposure\" : {\"None\" : 0,\"No\":1, \"Mn\" : 2, \"Av\": 3, \"Gd\" : 4},\n",
    "                       \"BsmtFinType1\" : {\"None\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4,\n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtFinType2\" : {\"None\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4,\n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtQual\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"FireplaceQu\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5,\n",
    "                                       \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n",
    "                       \"GarageCond\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"GarageQual\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"LandSlope\" : {\"Sev\" : 3, \"Mod\" : 2, \"Gtl\" : 1},\n",
    "                       \"LotShape\" : {\"IR3\" : 4, \"IR2\" : 3, \"IR1\" : 2, \"Reg\" : 1},\n",
    "                       \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n",
    "                       \"PoolQC\" : {\"None\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n",
    "                       \"Street\" : {\"Grvl\" : 1, \"Pave\" : 2}})\n",
    "    \n",
    "\n",
    "    \n",
    "    # Year processing \n",
    "    # Combine year sold with year build to year old\n",
    "    df_processed['YearsOld']  = df_processed['YrSold'] - df_processed['YearBuilt']\n",
    "    df_processed = df_processed.drop(['YearBuilt'], axis=1)\n",
    "\n",
    "    # Combine YrSold and YearRemodAdd\n",
    "    df_processed['YearSinceRemodel'] = df_processed['YrSold'] - df_processed['YearRemodAdd']\n",
    "    df_processed = df_processed.drop(['YearRemodAdd'], axis=1)\n",
    "    df_processed = df_processed.drop(['YrSold'], axis=1)\n",
    "    \n",
    "    # Missing rate greater than 47%, and low correlation with sale price\n",
    "    df_processed = df_processed.drop(['FireplaceQu'], axis=1)\n",
    "\n",
    "    # PoolQC has .99 missing value. drop will lower rmse\n",
    "    df_processed = df_processed.drop(['PoolQC'], axis=1)\n",
    "    \n",
    "#     MiscVal is 0 when MiscFeature is missing. drop will lower rmse a little\n",
    "#     df_processed = df_processed.drop(['MiscVal'], axis=1)\n",
    "    \n",
    "    #Get Dummies \n",
    "    df_processed = pd.get_dummies(df_processed, columns=df_processed.select_dtypes(include=['object']).columns, drop_first=True)\n",
    "\n",
    "    # Split train and test data sets\n",
    "    df_processed_train = df_processed[df_processed.index <= 1460].copy()\n",
    "    df_processed_test = df_processed[df_processed.index > 1460].copy()\n",
    "    \n",
    "    # take log on price\n",
    "    sale_price_train = np.log(sale_price_train)\n",
    "    df_processed_train['SalePrice'] = sale_price_train    \n",
    "    \n",
    "    if test is False:\n",
    "        return df_processed_train\n",
    "    if test is True:\n",
    "        return df_processed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for train set: 0.950989\n",
      "--------------------------------------------------\n",
      "R^2 for test  set: 0.932012\n",
      "--------------------------------------------------\n",
      "RMSE for test  set: 0.102994\n"
     ]
    }
   ],
   "source": [
    "train_linear( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow Training\n",
    "def train_linear( ):\n",
    "    import os\n",
    "    import warnings\n",
    "    import sys\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    import mlflow\n",
    "    import mlflow.sklearn\n",
    "    \n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.WARN)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    #from data_processing import data_process\n",
    "\n",
    "    def eval_metrics(actual, pred):\n",
    "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "        r2 = r2_score(actual, pred)\n",
    "        return rmse, r2\n",
    "\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "\n",
    "#     # Read the file\n",
    "#     try:\n",
    "#         df_raw = pd.read_csv('train.csv',index_col=0)\n",
    "#     except Exception as e:\n",
    "#         logger.exception(\n",
    "#             \"Unable to download training & test CSV, check your internet connection. Error: %s\", e)\n",
    "        \n",
    "    # Data processing.\n",
    "    df_processed = data_process()\n",
    "    \n",
    "    # The predicted column is \"SalePrice\" , split the data into training and test sets. (0.75, 0.25) split.\n",
    "    x_m = df_processed.drop([\"SalePrice\"], axis=1)\n",
    "    y_m = df_processed.loc[:,'SalePrice']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_m, y_m, test_size=0.2, random_state=42)\n",
    "      \n",
    "    \n",
    "    # Execute linear regression\n",
    "    with mlflow.start_run():\n",
    "        ols = LinearRegression()\n",
    "        ols.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate Metrics\n",
    "        rmse = sqrt(mean_squared_error(y_test, ols.predict(X_test)))\n",
    "\n",
    "        # Print out metrics\n",
    "        print(\"R^2 for train set: %f\" %ols.score(X_train, y_train))\n",
    "        print('-'*50)\n",
    "        print(\"R^2 for test  set: %f\" %ols.score(X_test, y_test))\n",
    "        print('-'*50)\n",
    "        print(\"RMSE for test  set: %f\" %rmse)\n",
    "\n",
    "        # Log parameter, metrics, and model to MLflow\n",
    "        mlflow.log_param(\"model\", 'linear_regression')\n",
    "        mlflow.log_metric(\"r2_train\", ols.score(X_train, y_train))\n",
    "        mlflow.log_metric(\"r2_test\", ols.score(X_test, y_test))\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "\n",
    "\n",
    "        mlflow.sklearn.log_model(ols, \"model\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run this line to test \n",
    "\n",
    "train_linear( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Error Normality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = ols.predict(X_test) - y_test\n",
    "print('The mean of the errors is %.4f' %np.mean(error))\n",
    "print('The standard deviation of the errors is %.4f' % np.std(error))\n",
    "print(\"Skewness: %f\" % error.skew())\n",
    "print(\"Kurtosis: %f\" % error.kurt())\n",
    "sns.distplot(error, fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(error, plot=plt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High Kurtosis means there are outliers for the model which are hard to fit in the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the outliers \n",
    "error.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constant Variance and Independent Errors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sub_error = error.sample(frac=0.5)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.xlim(-0.4, 0.4)\n",
    "plt.ylim(0, 4.3)\n",
    "\n",
    "my_norm = stats.norm(np.mean(error), np.std(error)).pdf\n",
    "label = 'All samples,\\nmean: %.4f, std: %.4f' % (np.mean(error), np.std(error))\n",
    "plt.plot(np.linspace(-0.4, 0.4), my_norm(np.linspace(-0.4, 0.4)), label=label)\n",
    "\n",
    "my_norm = stats.norm(np.mean(sub_error), np.std(sub_error)).pdf\n",
    "label = 'Half samples,\\nmean: %.4f, std: %.4f' % (np.mean(sub_error), np.std(sub_error))\n",
    "plt.plot(np.linspace(-0.4, 0.4), my_norm(np.linspace(-0.4, 0.4)), color='green', label=label)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
