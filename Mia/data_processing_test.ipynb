{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matplotlib\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "def data_process(test = False):\n",
    "    \n",
    "    \n",
    "\t# Read file for train or test.\n",
    "    if test:\n",
    "        df_raw = pd.read_csv('test.csv',index_col=0)\n",
    "    else:\n",
    "        df_raw = pd.read_csv('train.csv',index_col=0)\n",
    "        \n",
    "\n",
    "\t# Make a copy so the original dataframe will not be altered.\n",
    "    df_processed = df_raw.copy()\n",
    "    \n",
    "    \n",
    "\t# Remove outliers.\n",
    "    if test is False:\n",
    "        outlier_list_scatter = [524, 1299]\n",
    "        outlier_list_hard_to_fit = [463, 31, 534, 1433, 739, 1159, 108, 1231, 971, 1424 ]\n",
    "        outlier_list = outlier_list_scatter + outlier_list_hard_to_fit\n",
    "        df_processed = df_processed.drop(outlier_list)\n",
    "\n",
    "\n",
    "    ## Missing values\n",
    "    \n",
    "    # 259 LotFrontage  - replace missing value with 0 \n",
    "#     df_processed.LotFrontage = df_processed.LotFrontage.fillna(0)\n",
    "    df_processed[\"LotFrontage\"] = df_processed.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    # 1369 Alley - replace with None\n",
    "    df_processed.Alley = df_processed.Alley.fillna('None')\n",
    "\n",
    "    # 8 MasVnrType and MasVnrArea - replace MasVnrType with None and MasVnrArea with 0\n",
    "    df_processed.MasVnrType = df_processed.MasVnrType.fillna('None')\n",
    "    df_processed.MasVnrArea = df_processed.MasVnrArea.fillna(0)\n",
    "\n",
    "    # 37 basement: BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2- replace with None\n",
    "    df_processed.BsmtQual = df_processed.BsmtQual.fillna('None')\n",
    "    df_processed.BsmtCond = df_processed.BsmtCond.fillna('None')\n",
    "    df_processed.BsmtExposure = df_processed.BsmtExposure.fillna('None')\n",
    "    df_processed.BsmtFinType1 = df_processed.BsmtFinType1.fillna('None')\n",
    "    df_processed.BsmtFinType2 = df_processed.BsmtFinType2.fillna('None')\n",
    "    df_processed.TotalBsmtSF = df_processed.TotalBsmtSF.fillna(0)\n",
    "    \n",
    "\n",
    "    # 690 FireplaceQu - replace with None\n",
    "    df_processed.FireplaceQu = df_processed.FireplaceQu.fillna('None')\n",
    "\n",
    "    # 81 Garage: GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond - replace with None and year with 0 \n",
    "    df_processed.GarageType = df_processed.GarageType.fillna('None')\n",
    "    df_processed.GarageFinish = df_processed.GarageFinish.fillna('None')\n",
    "    df_processed.GarageQual = df_processed.GarageQual.fillna('None')\n",
    "    df_processed.GarageCond = df_processed.GarageCond.fillna('None')\n",
    "    df_processed.GarageYrBlt = df_processed.GarageYrBlt.fillna(0)\n",
    "\n",
    "    # 1453 PoolQC - replace with None\n",
    "    df_processed.PoolQC = df_processed.PoolQC.fillna('None')\n",
    "\n",
    "    # 1179 Fence - replace with None\n",
    "    df_processed.Fence = df_processed.Fence.fillna('None')\n",
    "\n",
    "    # 1406 MiscFeature - replace with None    \n",
    "    df_processed.MiscFeature = df_processed.MiscFeature.fillna('None')\n",
    "\n",
    "    # 1 Electrical\n",
    "    df_processed = df_processed[pd.notnull(df_processed.Electrical)]\n",
    "\n",
    "    ## Combine columns and drop multicollinear columns \n",
    "    \n",
    "    # combine bathroom quanlitity \n",
    "    df_processed['BsmtBath'] = df_processed.BsmtFullBath + df_processed.BsmtHalfBath * 0.5\n",
    "    df_processed['Bath'] = df_processed.FullBath + df_processed.HalfBath * 0.5\n",
    "    df_processed = df_processed.drop(['BsmtFullBath', 'BsmtHalfBath','FullBath','HalfBath'], axis=1)\n",
    "\n",
    "    # drop TotalBsmtSF - multicollinearaty\n",
    "    #df_processed = df_processed.drop(['TotalBsmtSF'], axis=1)\n",
    "\n",
    "    # drop GrLivArea - multicollinearaty\n",
    "    #df_processed = df_processed.drop(['GrLivArea'], axis=1)\n",
    "\n",
    "    # drop GarageArea - higher correlation than GarageACars, results are better as well\n",
    "    df_processed = df_processed.drop(['GarageArea'], axis=1) \n",
    "    df_processed = df_processed.drop(['MiscFeature'], axis=1) \n",
    "#     df_processed = df_processed.drop(['1stFlrSF'], axis=1) \n",
    "    df_processed = df_processed.drop(['TotRmsAbvGrd'], axis=1) \n",
    "\n",
    "    \n",
    "\t# Feature Transformation - take the logarithm of the features.\n",
    "    #Linear_Num_Cols = ['TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'LotArea', 'GarageArea', 'TotRmsAbvGrd', 'TotalSF', 'BsmtFinSF1']\n",
    "    if test is False:\n",
    "        df_processed.SalePrice = np.log(df_processed.SalePrice)\n",
    "    df_processed.GrLivArea = np.log(df_processed.GrLivArea)\n",
    "    df_processed.TotalBsmtSF = np.log(df_processed.TotalBsmtSF+1)\n",
    "#     df_processed.LotArea = np.log(df_processed.LotArea) -- performance decreases\n",
    "#     df_processed.GarageArea = np.log(df_processed.GarageArea) -- will drop column \n",
    "\n",
    "\n",
    "\n",
    "\t# Categorical Features Processsing\n",
    "\n",
    "\t# MSSubClass processing - MSSubClass 20-90 contains only duplicate information with HouseStyle and YearBuilt.\n",
    "    df_processed['MSSubClass'] = df_processed['MSSubClass'].replace(['20','30','40','45','50','60','70','75','80','85'], '0')\n",
    "\n",
    "    # Convert numerical to categorical. \n",
    "#     df_processed[['MSSubClass','OverallQual','OverallCond']] = df_processed[['MSSubClass','OverallQual','OverallCond']].astype(str)\n",
    "    df_processed['MSSubClass'] = df_processed['MSSubClass'].astype(str)\n",
    "\n",
    "    #Encode some categorical features as ordered numbers when there is information in the order.\n",
    "    df_processed = df_processed.replace({\"Alley\" : {\"None\":0,\"Grvl\" : 1, \"Pave\" : 2},\n",
    "                       \"BsmtCond\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"BsmtExposure\" : {\"None\" : 0,\"No\":1, \"Mn\" : 2, \"Av\": 3, \"Gd\" : 4},\n",
    "                       \"BsmtFinType1\" : {\"None\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4,\n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtFinType2\" : {\"None\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4,\n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                       \"BsmtQual\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                       \"FireplaceQu\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5,\n",
    "                                       \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n",
    "                       \"GarageCond\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"GarageQual\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                       \"LandSlope\" : {\"Sev\" : 1, \"Mod\" : 2, \"Gtl\" : 3},\n",
    "                       \"LotShape\" : {\"IR3\" : 1, \"IR2\" : 2, \"IR1\" : 3, \"Reg\" : 4},\n",
    "                       \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n",
    "                       \"PoolQC\" : {\"None\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n",
    "                       \"Street\" : {\"Grvl\" : 1, \"Pave\" : 2}})\n",
    "    \n",
    "### huimin please add new feature engineering here :)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #Get Dummies \n",
    "    df_processed = pd.get_dummies(df_processed, columns=df_processed.select_dtypes(include=['object']).columns, drop_first=True)\n",
    "\n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow Training\n",
    "def train_linear( ):\n",
    "    import os\n",
    "    import warnings\n",
    "    import sys\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    import mlflow\n",
    "    import mlflow.sklearn\n",
    "    \n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.WARN)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    #from data_processing import data_process\n",
    "\n",
    "    def eval_metrics(actual, pred):\n",
    "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "        r2 = r2_score(actual, pred)\n",
    "        return rmse, r2\n",
    "\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "\n",
    "#     # Read the file\n",
    "#     try:\n",
    "#         df_raw = pd.read_csv('train.csv',index_col=0)\n",
    "#     except Exception as e:\n",
    "#         logger.exception(\n",
    "#             \"Unable to download training & test CSV, check your internet connection. Error: %s\", e)\n",
    "        \n",
    "    # Data processing.\n",
    "    df_processed = data_process()\n",
    "    \n",
    "    # The predicted column is \"SalePrice\" , split the data into training and test sets. (0.75, 0.25) split.\n",
    "    x_m = df_processed.drop([\"SalePrice\"], axis=1)\n",
    "    y_m = df_processed.loc[:,'SalePrice']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_m, y_m, test_size=0.2, random_state=42)\n",
    "      \n",
    "    \n",
    "    # Execute linear regression\n",
    "    with mlflow.start_run():\n",
    "        ols = LinearRegression()\n",
    "        ols.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate Metrics\n",
    "        rmse = sqrt(mean_squared_error(y_test, ols.predict(X_test)))\n",
    "\n",
    "        # Print out metrics\n",
    "        print(\"R^2 for train set: %f\" %ols.score(X_train, y_train))\n",
    "        print('-'*50)\n",
    "        print(\"R^2 for test  set: %f\" %ols.score(X_test, y_test))\n",
    "        print('-'*50)\n",
    "        print(\"RMSE for test  set: %f\" %rmse)\n",
    "\n",
    "        # Log parameter, metrics, and model to MLflow\n",
    "        mlflow.log_param(\"model\", 'linear_regression')\n",
    "        mlflow.log_metric(\"r2_train\", ols.score(X_train, y_train))\n",
    "        mlflow.log_metric(\"r2_test\", ols.score(X_test, y_test))\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "\n",
    "\n",
    "        mlflow.sklearn.log_model(ols, \"model\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for train set: 0.951070\n",
      "--------------------------------------------------\n",
      "R^2 for test  set: 0.931034\n",
      "--------------------------------------------------\n",
      "RMSE for test  set: 0.103733\n"
     ]
    }
   ],
   "source": [
    "## run this line to test \n",
    "\n",
    "train_linear( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Error Normality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5f1d815cfc66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The mean of the errors is %.4f'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The standard deviation of the errors is %.4f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Skewness: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mskew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Kurtosis: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkurt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ols' is not defined"
     ]
    }
   ],
   "source": [
    "error = ols.predict(X_test) - y_test\n",
    "print('The mean of the errors is %.4f' %np.mean(error))\n",
    "print('The standard deviation of the errors is %.4f' % np.std(error))\n",
    "print(\"Skewness: %f\" % error.skew())\n",
    "print(\"Kurtosis: %f\" % error.kurt())\n",
    "sns.distplot(error, fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(error, plot=plt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High Kurtosis means there are outliers for the model which are hard to fit in the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the outliers \n",
    "error.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constant Variance and Independent Errors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sub_error = error.sample(frac=0.5)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.xlim(-0.4, 0.4)\n",
    "plt.ylim(0, 4.3)\n",
    "\n",
    "my_norm = stats.norm(np.mean(error), np.std(error)).pdf\n",
    "label = 'All samples,\\nmean: %.4f, std: %.4f' % (np.mean(error), np.std(error))\n",
    "plt.plot(np.linspace(-0.4, 0.4), my_norm(np.linspace(-0.4, 0.4)), label=label)\n",
    "\n",
    "my_norm = stats.norm(np.mean(sub_error), np.std(sub_error)).pdf\n",
    "label = 'Half samples,\\nmean: %.4f, std: %.4f' % (np.mean(sub_error), np.std(sub_error))\n",
    "plt.plot(np.linspace(-0.4, 0.4), my_norm(np.linspace(-0.4, 0.4)), color='green', label=label)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
