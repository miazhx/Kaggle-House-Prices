{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode)56-b12)\n",
      "  Starting server from C:\\Users\\miazh_000\\Anaconda3\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\MIAZH_~1\\AppData\\Local\\Temp\\tmpf9jb6qle\n",
      "  JVM stdout: C:\\Users\\MIAZH_~1\\AppData\\Local\\Temp\\tmpf9jb6qle\\h2o_miazh_000_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\MIAZH_~1\\AppData\\Local\\Temp\\tmpf9jb6qle\\h2o_miazh_000_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>24 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.26.0.10</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>11 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_miazh_000_y3g3zi</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.761 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>{'http': None, 'https': None}</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.3 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O cluster uptime:         24 secs\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.26.0.10\n",
       "H2O cluster version age:    11 days\n",
       "H2O cluster name:           H2O_from_python_miazh_000_y3g3zi\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.761 Gb\n",
       "H2O cluster total cores:    0\n",
       "H2O cluster allowed cores:  0\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:       {'http': None, 'https': None}\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python version:             3.7.3 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "import random\n",
    "import mlflow\n",
    "import mlflow.h2o\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "h2o.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(df_raw,remove_outlier = False,remove_hard_to_fit = False,linear_model = False):\n",
    "\n",
    "\t# Make a copy so the original dataframe will not be altered.\n",
    "    df_processed = df_raw.copy()\n",
    "\n",
    "\t# Feature Transformation - take the logarithm of the features to meet normality assumptions.\n",
    "    df_processed.SalePrice = np.log(df_processed.SalePrice)\n",
    "    df_processed.GrLivArea = np.log(df_processed.GrLivArea)\n",
    "    \n",
    "\t# Remove outliers.\n",
    "    outlier_list = [524, 1299, 463, 31, 534, 1433, 739, 1159, 108, 1231, 971, 1424]\n",
    "    df_processed = df_processed.drop(outlier_list)\n",
    "\n",
    "    ## Missing values\n",
    "    \n",
    "    # 259 LotFrontage  - replace missing value with 0 \n",
    "#     df_processed.LotFrontage = df_processed.LotFrontage.fillna(0)\n",
    "\n",
    "    # 1369 Alley - replace with None\n",
    "#     df_processed.Alley = df_processed.Alley.fillna('None')\n",
    "\n",
    "    # 8 MasVnrType and MasVnrArea - replace MasVnrType with None and MasVnrArea with 0\n",
    "#     df_processed.MasVnrType = df_processed.MasVnrType.fillna('None')\n",
    "#     df_processed.MasVnrArea = df_processed.MasVnrArea.fillna(0)\n",
    "\n",
    "    # 37 basement: BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2- replace with Nb\n",
    "#     df_processed.BsmtQual = df_processed.BsmtQual.fillna('Nb')\n",
    "#     df_processed.BsmtCond = df_processed.BsmtCond.fillna('Nb')\n",
    "#     df_processed.BsmtExposure = df_processed.BsmtExposure.fillna('Nb')\n",
    "#     df_processed.BsmtFinType1 = df_processed.BsmtFinType1.fillna('Nb')\n",
    "#     df_processed.BsmtFinType2 = df_processed.BsmtFinType2.fillna('Nb')\n",
    "\n",
    "    # 690 FireplaceQu - replace with Nf\n",
    "#     df_processed.FireplaceQu = df_processed.FireplaceQu.fillna('Nf')\n",
    "\n",
    "    # 81 Garage: GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond - replace with Ng and year with 0 \n",
    "#     df_processed.GarageType = df_processed.GarageType.fillna('Ng')\n",
    "#     df_processed.GarageFinish = df_processed.GarageFinish.fillna('Ng')\n",
    "#     df_processed.GarageQual = df_processed.GarageQual.fillna('Ng')\n",
    "#     df_processed.GarageCond = df_processed.GarageCond.fillna('Ng')\n",
    "#     df_processed.GarageYrBlt = df_processed.GarageYrBlt.fillna(0)\n",
    "\n",
    "    # 1453 PoolQC - replace with Np\n",
    "#     df_processed.PoolQC = df_processed.PoolQC.fillna('Np')\n",
    "\n",
    "    # 1179 Fence - replace with Nf\n",
    "#     df_processed.Fence = df_processed.Fence.fillna('Nf')\n",
    "\n",
    "    # 1406 MiscFeature - replace with None    \n",
    "#     df_processed.MiscFeature = df_processed.MiscFeature.fillna('None')\n",
    "\n",
    "    # 1 Electrical\n",
    "#     df_processed = df_processed[pd.notnull(df_processed.Electrical)]\n",
    "\n",
    "    ## Combine columns and drop multicollinear columns \n",
    "    \n",
    "    # combine bathroom quanlitity \n",
    "    df_processed['BsmtBath'] = df_processed.BsmtFullBath + df_processed.BsmtHalfBath * 0.5\n",
    "    df_processed['Bath'] = df_processed.FullBath + df_processed.HalfBath * 0.5\n",
    "    df_processed = df_processed.drop(['BsmtFullBath', 'BsmtHalfBath','FullBath','HalfBath'], axis=1)\n",
    "\n",
    "    # drop TotalBsmtSF - multicollinearaty\n",
    "    #df_processed = df_processed.drop(['TotalBsmtSF'], axis=1)\n",
    "\n",
    "    # drop GrLivArea - multicollinearaty\n",
    "    #df_processed = df_processed.drop(['GrLivArea'], axis=1)\n",
    "\n",
    "    # drop GarageArea - higher correlation than GarageACars, results are better as well\n",
    "    #df_processed = df_processed.drop(['GarageArea'], axis=1) \n",
    "    \n",
    "    \n",
    "    # drop Id\n",
    "    df_processed = df_processed.drop(['Id'], axis=1)\n",
    "\n",
    "\t# Categorical Features Processsing\n",
    "\n",
    "\t# MSSubClass processing - MSSubClass 20-90 contains only duplicate information with HouseStyle and YearBuilt.\n",
    "    #df_processed['MSSubClass'] = df_processed['MSSubClass'].replace(['20','30','40','45','50','60','70','75','80','85'], '0')\n",
    "\n",
    "    # Convert numerical to categorical. \n",
    "    #df_processed[['MSSubClass','OverallQual','OverallCond']] = df_processed[['MSSubClass','OverallQual','OverallCond']].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "    return df_processed.to_csv('processed_rf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_process(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "df_rf = h2o.import_file(path=\"processed_rf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = df_rf['SalePrice'].runif()\n",
    "train = df_rf[r  < 0.7]\n",
    "test  = df_rf[0.3 <= r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(ntrees):\n",
    "    with mlflow.start_run():\n",
    "        rf = H2ORandomForestEstimator(ntrees=ntrees,max_depth=max_depth)\n",
    "        train_cols = [n for n in df_rf.col_names if n != \"SalePrice\"]\n",
    "        rf.train(train_cols, \"SalePrice\", training_frame=train, validation_frame=test)\n",
    "        #add oor\n",
    "        mlflow.log_param(\"model\", 'random forest')\n",
    "        mlflow.log_param(\"ntrees\", ntrees)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        \n",
    "        mlflow.log_metric(\"rmse\", rf.rmse())\n",
    "        mlflow.log_metric(\"r2\", rf.r2())\n",
    "        #mlflow.log_metric(\"mae\", rf.mae())\n",
    "        \n",
    "        mlflow.h2o.log_model(rf, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |████████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "for ntrees in [50, 100, 200, 400]:\n",
    "    for max_depth in [10, 15, 20, 30]:\n",
    "        train_random_forest(ntrees)\n",
    "        \n",
    "        \n",
    "#max features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yaml.safe_dump"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
