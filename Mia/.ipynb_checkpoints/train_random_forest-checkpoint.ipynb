{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "import random\n",
    "import mlflow\n",
    "import mlflow.h2o\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(df_raw,remove_outlier = False,remove_hard_to_fit = False,linear_model = False):\n",
    "\n",
    "\t# Make a copy so the original dataframe will not be altered.\n",
    "    df_processed = df_raw.copy()\n",
    "\n",
    "\t# Feature Transformation - take the logarithm of the features to meet normality assumptions.\n",
    "    df_processed.SalePrice = np.log(df_processed.SalePrice)\n",
    "    df_processed.GrLivArea = np.log(df_processed.GrLivArea)\n",
    "    \n",
    "\t# Remove outliers.\n",
    "    outlier_list = [524, 1299, 463, 31, 534, 1433, 739, 1159, 108, 1231, 971, 1424]\n",
    "    df_processed = df_processed.drop(outlier_list)\n",
    "\n",
    "    ## Missing values\n",
    "    \n",
    "    # 259 LotFrontage  - replace missing value with 0 \n",
    "#     df_processed.LotFrontage = df_processed.LotFrontage.fillna(0)\n",
    "\n",
    "    # 1369 Alley - replace with None\n",
    "#     df_processed.Alley = df_processed.Alley.fillna('None')\n",
    "\n",
    "    # 8 MasVnrType and MasVnrArea - replace MasVnrType with None and MasVnrArea with 0\n",
    "#     df_processed.MasVnrType = df_processed.MasVnrType.fillna('None')\n",
    "#     df_processed.MasVnrArea = df_processed.MasVnrArea.fillna(0)\n",
    "\n",
    "    # 37 basement: BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2- replace with Nb\n",
    "#     df_processed.BsmtQual = df_processed.BsmtQual.fillna('Nb')\n",
    "#     df_processed.BsmtCond = df_processed.BsmtCond.fillna('Nb')\n",
    "#     df_processed.BsmtExposure = df_processed.BsmtExposure.fillna('Nb')\n",
    "#     df_processed.BsmtFinType1 = df_processed.BsmtFinType1.fillna('Nb')\n",
    "#     df_processed.BsmtFinType2 = df_processed.BsmtFinType2.fillna('Nb')\n",
    "\n",
    "    # 690 FireplaceQu - replace with Nf\n",
    "#     df_processed.FireplaceQu = df_processed.FireplaceQu.fillna('Nf')\n",
    "\n",
    "    # 81 Garage: GarageType, GarageYrBlt, GarageFinish, GarageQual, GarageCond - replace with Ng and year with 0 \n",
    "#     df_processed.GarageType = df_processed.GarageType.fillna('Ng')\n",
    "#     df_processed.GarageFinish = df_processed.GarageFinish.fillna('Ng')\n",
    "#     df_processed.GarageQual = df_processed.GarageQual.fillna('Ng')\n",
    "#     df_processed.GarageCond = df_processed.GarageCond.fillna('Ng')\n",
    "#     df_processed.GarageYrBlt = df_processed.GarageYrBlt.fillna(0)\n",
    "\n",
    "    # 1453 PoolQC - replace with Np\n",
    "#     df_processed.PoolQC = df_processed.PoolQC.fillna('Np')\n",
    "\n",
    "    # 1179 Fence - replace with Nf\n",
    "#     df_processed.Fence = df_processed.Fence.fillna('Nf')\n",
    "\n",
    "    # 1406 MiscFeature - replace with None    \n",
    "#     df_processed.MiscFeature = df_processed.MiscFeature.fillna('None')\n",
    "\n",
    "    # 1 Electrical\n",
    "#     df_processed = df_processed[pd.notnull(df_processed.Electrical)]\n",
    "\n",
    "    ## Combine columns and drop multicollinear columns \n",
    "    \n",
    "    # combine bathroom quanlitity \n",
    "    df_processed['BsmtBath'] = df_processed.BsmtFullBath + df_processed.BsmtHalfBath * 0.5\n",
    "    df_processed['Bath'] = df_processed.FullBath + df_processed.HalfBath * 0.5\n",
    "    df_processed = df_processed.drop(['BsmtFullBath', 'BsmtHalfBath','FullBath','HalfBath'], axis=1)\n",
    "\n",
    "    # drop TotalBsmtSF - multicollinearaty\n",
    "    #df_processed = df_processed.drop(['TotalBsmtSF'], axis=1)\n",
    "\n",
    "    # drop GrLivArea - multicollinearaty\n",
    "    #df_processed = df_processed.drop(['GrLivArea'], axis=1)\n",
    "\n",
    "    # drop GarageArea - higher correlation than GarageACars, results are better as well\n",
    "    #df_processed = df_processed.drop(['GarageArea'], axis=1) \n",
    "    \n",
    "    \n",
    "    # drop Id\n",
    "    df_processed = df_processed.drop(['Id'], axis=1)\n",
    "\n",
    "\t# Categorical Features Processsing\n",
    "\n",
    "\t# MSSubClass processing - MSSubClass 20-90 contains only duplicate information with HouseStyle and YearBuilt.\n",
    "    #df_processed['MSSubClass'] = df_processed['MSSubClass'].replace(['20','30','40','45','50','60','70','75','80','85'], '0')\n",
    "\n",
    "    # Convert numerical to categorical. \n",
    "    #df_processed[['MSSubClass','OverallQual','OverallCond']] = df_processed[['MSSubClass','OverallQual','OverallCond']].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "    return df_processed.to_csv('processed_rf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_process(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "H2OConnectionError",
     "evalue": "Not connected to a cluster. Did you run `h2o.connect()`?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mH2OConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-eb755e9da473>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"processed_rf.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h2o\\h2o.py\u001b[0m in \u001b[0;36mimport_file\u001b[1;34m(path, destination_frame, parse, header, sep, col_names, col_types, na_strings, pattern, skipped_columns, custom_non_data_line_markers)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         return H2OFrame()._import_parse(path, pattern, destination_frame, header, sep, col_names, col_types, na_strings,\n\u001b[1;32m--> 440\u001b[1;33m                                         skipped_columns, custom_non_data_line_markers)\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h2o\\frame.py\u001b[0m in \u001b[0;36m_import_parse\u001b[1;34m(self, path, pattern, destination_frame, header, separator, column_names, column_types, na_strings, skipped_columns, custom_non_data_line_markers)\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mH2OFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__LOCAL_EXPANSION_ON_SINGLE_IMPORT__\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"://\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# fixme: delete those 2 lines, cf. PUBDEV-5717\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m         \u001b[0mrawkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m         self._parse(rawkey, destination_frame, header, separator, column_names, column_types, na_strings,\n\u001b[0;32m    338\u001b[0m                     skipped_columns, custom_non_data_line_markers)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h2o\\h2o.py\u001b[0m in \u001b[0;36mlazy_import\u001b[1;34m(path, pattern)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[0massert_is_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[0mpaths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_import_multi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h2o\\h2o.py\u001b[0m in \u001b[0;36m_import_multi\u001b[1;34m(paths, pattern)\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[0massert_is_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[0massert_is_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m     \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"POST /3/ImportFilesMulti\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"paths\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pattern\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"fails\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ImportFiles of '\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"' failed on \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"fails\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"destination_frames\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h2o\\h2o.py\u001b[0m in \u001b[0;36mapi\u001b[1;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \"\"\"\n\u001b[0;32m    102\u001b[0m     \u001b[1;31m# type checks are performed in H2OConnection class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m     \u001b[0m_check_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mh2oconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h2o\\h2o.py\u001b[0m in \u001b[0;36m_check_connection\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1645\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_check_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1646\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mh2oconn\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mh2oconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1647\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mH2OConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Not connected to a cluster. Did you run `h2o.connect()`?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1649\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_connect_with_conf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_conf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mH2OConnectionError\u001b[0m: Not connected to a cluster. Did you run `h2o.connect()`?"
     ]
    }
   ],
   "source": [
    "df_rf = h2o.import_file(path=\"processed_rf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = df_rf['SalePrice'].runif()\n",
    "train = df_rf[r  < 0.7]\n",
    "test  = df_rf[0.3 <= r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(ntrees):\n",
    "    with mlflow.start_run():\n",
    "        rf = H2ORandomForestEstimator(ntrees=ntrees,max_depth=max_depth)\n",
    "        train_cols = [n for n in df_rf.col_names if n != \"SalePrice\"]\n",
    "        rf.train(train_cols, \"SalePrice\", training_frame=train, validation_frame=test)\n",
    "        #add oor\n",
    "        mlflow.log_param(\"ntrees\", ntrees)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        \n",
    "        mlflow.log_metric(\"rmse\", rf.rmse())\n",
    "        mlflow.log_metric(\"r2\", rf.r2())\n",
    "        #mlflow.log_metric(\"mae\", rf.mae())\n",
    "        \n",
    "        mlflow.h2o.log_model(rf, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ntrees in [50, 100, 200, 400]:\n",
    "    for max_depth in [10, 15, 20, 30]:\n",
    "        train_random_forest(ntrees)\n",
    "        \n",
    "        \n",
    "#max features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yaml.safe_dump"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
